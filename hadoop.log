2016-02-16 12:46:54,455 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 12:46:55,434 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 12:46:55,436 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 12:46:56,788 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 12:46:56,804 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 12:46:56,852 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 12:46:56,930 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 12:46:57,353 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local554019886_0001
2016-02-16 12:46:58,332 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 12:46:58,333 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local554019886_0001
2016-02-16 12:46:58,345 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 12:46:58,371 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:46:58,378 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 12:46:58,659 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 12:46:58,660 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local554019886_0001_m_000000_0
2016-02-16 12:46:58,791 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:46:58,827 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 12:46:58,831 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 12:46:58,979 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 12:46:58,979 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 12:46:58,979 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 12:46:58,980 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 12:46:58,980 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 12:46:58,988 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 12:46:59,006 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 12:46:59,015 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 12:46:59,018 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local554019886_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.IntWritable, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.IntWritable, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:39)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 12:46:59,344 INFO org.apache.hadoop.mapreduce.Job: Job job_local554019886_0001 running in uber mode : false
2016-02-16 12:46:59,345 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 12:46:59,349 INFO org.apache.hadoop.mapreduce.Job: Job job_local554019886_0001 failed with state FAILED due to: NA
2016-02-16 12:46:59,361 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 12:50:04,504 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 12:50:05,154 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 12:50:05,163 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 12:50:05,867 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 12:50:05,871 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 12:50:05,885 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 12:50:05,940 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 12:50:06,246 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1557910880_0001
2016-02-16 12:50:06,847 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 12:50:06,848 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1557910880_0001
2016-02-16 12:50:06,858 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 12:50:06,878 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:50:06,887 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 12:50:07,074 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 12:50:07,075 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1557910880_0001_m_000000_0
2016-02-16 12:50:07,148 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:50:07,188 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 12:50:07,194 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 12:50:07,341 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 12:50:07,341 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 12:50:07,341 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 12:50:07,341 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 12:50:07,341 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 12:50:07,355 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 12:50:07,378 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 12:50:07,395 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 12:50:07,397 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1557910880_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.IntWritable, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.IntWritable, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:39)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 12:50:07,852 INFO org.apache.hadoop.mapreduce.Job: Job job_local1557910880_0001 running in uber mode : false
2016-02-16 12:50:07,853 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 12:50:07,855 INFO org.apache.hadoop.mapreduce.Job: Job job_local1557910880_0001 failed with state FAILED due to: NA
2016-02-16 12:50:07,860 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 12:52:24,491 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 12:52:25,297 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 12:52:25,300 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 12:52:26,411 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 12:52:26,432 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 12:52:26,478 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 12:52:26,569 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 12:52:26,929 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local2056494418_0001
2016-02-16 12:52:27,610 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 12:52:27,611 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local2056494418_0001
2016-02-16 12:52:27,614 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 12:52:27,636 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:52:27,639 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 12:52:27,843 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 12:52:27,845 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2056494418_0001_m_000000_0
2016-02-16 12:52:27,899 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:52:27,916 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 12:52:27,921 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 12:52:28,024 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 12:52:28,024 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 12:52:28,025 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 12:52:28,025 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 12:52:28,025 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 12:52:28,028 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 12:52:28,044 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 12:52:28,044 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 12:52:28,044 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 12:52:28,049 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 305; bufvoid = 104857600
2016-02-16 12:52:28,050 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2016-02-16 12:52:28,059 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 12:52:28,063 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2056494418_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 12:52:28,072 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 12:52:28,073 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2056494418_0001_m_000000_0' done.
2016-02-16 12:52:28,073 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2056494418_0001_m_000000_0
2016-02-16 12:52:28,073 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 12:52:28,077 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 12:52:28,078 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2056494418_0001_r_000000_0
2016-02-16 12:52:28,086 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:52:28,087 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 12:52:28,090 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@22c296dd
2016-02-16 12:52:28,104 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 12:52:28,110 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2056494418_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 12:52:28,162 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2056494418_0001_m_000000_0 decomp: 337 len: 341 to MEMORY
2016-02-16 12:52:28,167 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 337 bytes from map-output for attempt_local2056494418_0001_m_000000_0
2016-02-16 12:52:28,169 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 337, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->337
2016-02-16 12:52:28,170 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 12:52:28,172 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 12:52:28,173 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 12:52:28,182 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 12:52:28,186 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 12:52:28,190 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 337 bytes to disk to satisfy reduce memory limit
2016-02-16 12:52:28,190 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 341 bytes from disk
2016-02-16 12:52:28,191 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 12:52:28,191 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 12:52:28,192 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 12:52:28,192 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 12:52:28,199 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 12:52:28,205 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 12:52:28,208 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local2056494418_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 12:52:28,622 INFO org.apache.hadoop.mapreduce.Job: Job job_local2056494418_0001 running in uber mode : false
2016-02-16 12:52:28,623 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 12:52:28,625 INFO org.apache.hadoop.mapreduce.Job: Job job_local2056494418_0001 failed with state FAILED due to: NA
2016-02-16 12:52:28,640 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263884
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=15
		Map output bytes=305
		Map output materialized bytes=341
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=341
		Reduce input records=0
		Reduce output records=0
		Spilled Records=15
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=41
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 12:53:35,714 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 12:53:36,394 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 12:53:36,397 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 12:53:36,505 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/Desktop/hw3_output already exists
2016-02-16 12:53:47,681 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 12:53:48,399 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 12:53:48,405 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 12:53:49,048 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 12:53:49,050 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 12:53:49,069 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 12:53:49,115 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 12:53:49,412 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local227941193_0001
2016-02-16 12:53:50,014 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 12:53:50,016 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local227941193_0001
2016-02-16 12:53:50,024 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 12:53:50,044 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:53:50,054 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 12:53:50,247 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 12:53:50,248 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local227941193_0001_m_000000_0
2016-02-16 12:53:50,319 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:53:50,366 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 12:53:50,374 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 12:53:50,535 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 12:53:50,536 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 12:53:50,536 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 12:53:50,536 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 12:53:50,536 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 12:53:50,547 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 12:53:50,580 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 12:53:50,580 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 12:53:50,580 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 12:53:50,584 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 305; bufvoid = 104857600
2016-02-16 12:53:50,584 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2016-02-16 12:53:50,605 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 12:53:50,617 INFO org.apache.hadoop.mapred.Task: Task:attempt_local227941193_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 12:53:50,640 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 12:53:50,640 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local227941193_0001_m_000000_0' done.
2016-02-16 12:53:50,644 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local227941193_0001_m_000000_0
2016-02-16 12:53:50,646 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 12:53:50,652 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 12:53:50,652 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local227941193_0001_r_000000_0
2016-02-16 12:53:50,670 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:53:50,670 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 12:53:50,679 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1d2a5fbb
2016-02-16 12:53:50,712 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 12:53:50,726 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local227941193_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 12:53:50,833 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local227941193_0001_m_000000_0 decomp: 337 len: 341 to MEMORY
2016-02-16 12:53:50,844 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 337 bytes from map-output for attempt_local227941193_0001_m_000000_0
2016-02-16 12:53:50,849 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 337, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->337
2016-02-16 12:53:50,851 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 12:53:50,854 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 12:53:50,854 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 12:53:50,868 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 12:53:50,869 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 12:53:50,872 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 337 bytes to disk to satisfy reduce memory limit
2016-02-16 12:53:50,873 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 341 bytes from disk
2016-02-16 12:53:50,873 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 12:53:50,876 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 12:53:50,877 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 12:53:50,878 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 12:53:50,894 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 12:53:50,904 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 12:53:50,907 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local227941193_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 12:53:51,020 INFO org.apache.hadoop.mapreduce.Job: Job job_local227941193_0001 running in uber mode : false
2016-02-16 12:53:51,027 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 12:53:51,028 INFO org.apache.hadoop.mapreduce.Job: Job job_local227941193_0001 failed with state FAILED due to: NA
2016-02-16 12:53:51,070 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262490
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=15
		Map output bytes=305
		Map output materialized bytes=341
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=341
		Reduce input records=0
		Reduce output records=0
		Spilled Records=15
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=68
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 12:55:32,312 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 12:55:33,009 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 12:55:33,010 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 12:55:33,927 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 12:55:33,940 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 12:55:33,988 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 12:55:34,170 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 12:55:34,552 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local667709065_0001
2016-02-16 12:55:35,248 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 12:55:35,249 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local667709065_0001
2016-02-16 12:55:35,251 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 12:55:35,273 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:55:35,276 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 12:55:35,458 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 12:55:35,459 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local667709065_0001_m_000000_0
2016-02-16 12:55:35,528 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:55:35,562 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 12:55:35,571 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 12:55:35,664 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 12:55:35,664 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 12:55:35,664 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 12:55:35,665 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 12:55:35,665 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 12:55:35,678 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 12:55:35,695 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 12:55:35,695 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 12:55:35,695 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 12:55:35,702 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 305; bufvoid = 104857600
2016-02-16 12:55:35,702 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2016-02-16 12:55:35,711 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 12:55:35,714 INFO org.apache.hadoop.mapred.Task: Task:attempt_local667709065_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 12:55:35,725 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 12:55:35,726 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local667709065_0001_m_000000_0' done.
2016-02-16 12:55:35,726 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local667709065_0001_m_000000_0
2016-02-16 12:55:35,726 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 12:55:35,734 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 12:55:35,734 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local667709065_0001_r_000000_0
2016-02-16 12:55:35,742 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:55:35,742 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 12:55:35,746 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42f599c6
2016-02-16 12:55:35,760 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 12:55:35,766 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local667709065_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 12:55:35,818 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local667709065_0001_m_000000_0 decomp: 337 len: 341 to MEMORY
2016-02-16 12:55:35,826 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 337 bytes from map-output for attempt_local667709065_0001_m_000000_0
2016-02-16 12:55:35,828 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 337, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->337
2016-02-16 12:55:35,831 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 12:55:35,832 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 12:55:35,832 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 12:55:35,841 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 12:55:35,842 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 12:55:35,843 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 337 bytes to disk to satisfy reduce memory limit
2016-02-16 12:55:35,843 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 341 bytes from disk
2016-02-16 12:55:35,844 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 12:55:35,845 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 12:55:35,845 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 12:55:35,846 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 12:55:35,853 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 12:55:35,859 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 12:55:35,862 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local667709065_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 12:55:36,259 INFO org.apache.hadoop.mapreduce.Job: Job job_local667709065_0001 running in uber mode : false
2016-02-16 12:55:36,260 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 12:55:36,261 INFO org.apache.hadoop.mapreduce.Job: Job job_local667709065_0001 failed with state FAILED due to: NA
2016-02-16 12:55:36,271 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262490
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=15
		Map output bytes=305
		Map output materialized bytes=341
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=341
		Reduce input records=0
		Reduce output records=0
		Spilled Records=15
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 12:56:39,086 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 12:56:39,753 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 12:56:39,754 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 12:56:40,491 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 12:56:40,496 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 12:56:40,516 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 12:56:40,569 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 12:56:40,867 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1107990788_0001
2016-02-16 12:56:41,507 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 12:56:41,508 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1107990788_0001
2016-02-16 12:56:41,512 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 12:56:41,532 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:56:41,537 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 12:56:41,714 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 12:56:41,715 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1107990788_0001_m_000000_0
2016-02-16 12:56:41,791 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:56:41,826 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 12:56:41,830 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 12:56:42,009 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 12:56:42,010 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 12:56:42,011 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 12:56:42,011 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 12:56:42,013 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 12:56:42,023 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 12:56:42,049 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 12:56:42,049 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 12:56:42,050 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 12:56:42,052 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 184; bufvoid = 104857600
2016-02-16 12:56:42,057 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214364(104857456); length = 33/6553600
2016-02-16 12:56:42,075 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 12:56:42,082 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1107990788_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 12:56:42,100 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 12:56:42,103 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1107990788_0001_m_000000_0' done.
2016-02-16 12:56:42,104 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1107990788_0001_m_000000_0
2016-02-16 12:56:42,104 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 12:56:42,107 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 12:56:42,108 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1107990788_0001_r_000000_0
2016-02-16 12:56:42,135 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 12:56:42,136 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 12:56:42,139 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42b5e6a1
2016-02-16 12:56:42,183 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 12:56:42,197 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1107990788_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 12:56:42,292 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1107990788_0001_m_000000_0 decomp: 204 len: 208 to MEMORY
2016-02-16 12:56:42,303 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 204 bytes from map-output for attempt_local1107990788_0001_m_000000_0
2016-02-16 12:56:42,304 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 204, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->204
2016-02-16 12:56:42,310 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 12:56:42,311 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 12:56:42,312 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 12:56:42,323 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 12:56:42,327 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 200 bytes
2016-02-16 12:56:42,328 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 204 bytes to disk to satisfy reduce memory limit
2016-02-16 12:56:42,328 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 208 bytes from disk
2016-02-16 12:56:42,329 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 12:56:42,330 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 12:56:42,331 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 200 bytes
2016-02-16 12:56:42,331 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 12:56:42,349 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 12:56:42,360 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 12:56:42,364 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1107990788_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 12:56:42,511 INFO org.apache.hadoop.mapreduce.Job: Job job_local1107990788_0001 running in uber mode : false
2016-02-16 12:56:42,515 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 12:56:42,518 INFO org.apache.hadoop.mapreduce.Job: Job job_local1107990788_0001 failed with state FAILED due to: NA
2016-02-16 12:56:42,546 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263751
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=9
		Map output bytes=184
		Map output materialized bytes=208
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=208
		Reduce input records=0
		Reduce output records=0
		Spilled Records=9
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=70
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 13:04:01,083 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 13:04:01,762 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 13:04:01,763 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 13:04:02,382 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 13:04:02,386 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 13:04:02,402 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 13:04:02,455 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 13:04:02,752 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1657215436_0001
2016-02-16 13:04:03,363 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 13:04:03,365 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1657215436_0001
2016-02-16 13:04:03,374 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 13:04:03,386 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:04:03,398 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 13:04:03,574 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 13:04:03,575 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1657215436_0001_m_000000_0
2016-02-16 13:04:03,657 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:04:03,696 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:04:03,702 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 13:04:03,872 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 13:04:03,875 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 13:04:03,878 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 13:04:03,879 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 13:04:03,879 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 13:04:03,889 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 13:04:03,920 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 13:04:03,920 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 13:04:03,921 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 13:04:03,928 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 184; bufvoid = 104857600
2016-02-16 13:04:03,929 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214364(104857456); length = 33/6553600
2016-02-16 13:04:03,953 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 13:04:03,962 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1657215436_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 13:04:03,981 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 13:04:03,986 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1657215436_0001_m_000000_0' done.
2016-02-16 13:04:03,988 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1657215436_0001_m_000000_0
2016-02-16 13:04:03,989 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 13:04:03,995 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 13:04:03,996 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1657215436_0001_r_000000_0
2016-02-16 13:04:04,015 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:04:04,016 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:04:04,024 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c91a704
2016-02-16 13:04:04,063 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 13:04:04,077 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1657215436_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 13:04:04,162 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1657215436_0001_m_000000_0 decomp: 204 len: 208 to MEMORY
2016-02-16 13:04:04,178 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 204 bytes from map-output for attempt_local1657215436_0001_m_000000_0
2016-02-16 13:04:04,184 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 204, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->204
2016-02-16 13:04:04,190 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 13:04:04,192 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:04:04,192 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 13:04:04,202 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:04:04,203 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 200 bytes
2016-02-16 13:04:04,207 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 204 bytes to disk to satisfy reduce memory limit
2016-02-16 13:04:04,207 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 208 bytes from disk
2016-02-16 13:04:04,211 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 13:04:04,211 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:04:04,212 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 200 bytes
2016-02-16 13:04:04,212 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:04:04,226 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 13:04:04,234 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 13:04:04,237 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1657215436_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 13:04:04,379 INFO org.apache.hadoop.mapreduce.Job: Job job_local1657215436_0001 running in uber mode : false
2016-02-16 13:04:04,380 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 13:04:04,381 INFO org.apache.hadoop.mapreduce.Job: Job job_local1657215436_0001 failed with state FAILED due to: NA
2016-02-16 13:04:04,400 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263751
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=9
		Map output bytes=184
		Map output materialized bytes=208
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=208
		Reduce input records=0
		Reduce output records=0
		Spilled Records=9
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=71
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 13:04:59,614 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 13:05:00,397 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 13:05:00,400 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 13:05:01,129 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 13:05:01,132 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 13:05:01,144 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 13:05:01,191 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 13:05:01,490 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local558527843_0001
2016-02-16 13:05:02,079 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 13:05:02,080 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local558527843_0001
2016-02-16 13:05:02,083 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 13:05:02,098 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:05:02,111 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 13:05:02,285 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 13:05:02,286 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local558527843_0001_m_000000_0
2016-02-16 13:05:02,363 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:05:02,407 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:05:02,415 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 13:05:02,596 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 13:05:02,596 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 13:05:02,600 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 13:05:02,601 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 13:05:02,601 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 13:05:02,614 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 13:05:02,652 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 13:05:02,652 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 13:05:02,652 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 13:05:02,656 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 305; bufvoid = 104857600
2016-02-16 13:05:02,657 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2016-02-16 13:05:02,683 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 13:05:02,691 INFO org.apache.hadoop.mapred.Task: Task:attempt_local558527843_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 13:05:02,715 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 13:05:02,721 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local558527843_0001_m_000000_0' done.
2016-02-16 13:05:02,721 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local558527843_0001_m_000000_0
2016-02-16 13:05:02,721 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 13:05:02,727 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 13:05:02,728 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local558527843_0001_r_000000_0
2016-02-16 13:05:02,747 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:05:02,747 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:05:02,756 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6d565f45
2016-02-16 13:05:02,787 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 13:05:02,799 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local558527843_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 13:05:02,895 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local558527843_0001_m_000000_0 decomp: 337 len: 341 to MEMORY
2016-02-16 13:05:02,902 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 337 bytes from map-output for attempt_local558527843_0001_m_000000_0
2016-02-16 13:05:02,908 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 337, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->337
2016-02-16 13:05:02,914 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 13:05:02,915 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:05:02,915 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 13:05:02,922 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:05:02,927 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 13:05:02,930 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 337 bytes to disk to satisfy reduce memory limit
2016-02-16 13:05:02,930 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 341 bytes from disk
2016-02-16 13:05:02,931 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 13:05:02,934 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:05:02,935 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 13:05:02,936 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:05:02,948 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 13:05:02,959 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 13:05:02,962 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local558527843_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 13:05:03,088 INFO org.apache.hadoop.mapreduce.Job: Job job_local558527843_0001 running in uber mode : false
2016-02-16 13:05:03,092 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 13:05:03,099 INFO org.apache.hadoop.mapreduce.Job: Job job_local558527843_0001 failed with state FAILED due to: NA
2016-02-16 13:05:03,124 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262490
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=15
		Map output bytes=305
		Map output materialized bytes=341
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=341
		Reduce input records=0
		Reduce output records=0
		Spilled Records=15
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=76
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 13:36:31,166 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 13:36:32,001 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 13:36:32,010 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 13:36:32,116 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/Desktop/hw3_output already exists
2016-02-16 13:40:13,063 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 13:40:13,776 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 13:40:13,777 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 13:40:14,735 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 13:40:14,745 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 13:40:14,780 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 13:40:14,876 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 13:40:15,179 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1819689952_0001
2016-02-16 13:40:15,775 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 13:40:15,776 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1819689952_0001
2016-02-16 13:40:15,783 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 13:40:15,802 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:40:15,811 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 13:40:15,993 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 13:40:15,994 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1819689952_0001_m_000000_0
2016-02-16 13:40:16,055 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:40:16,073 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:40:16,076 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 13:40:16,194 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 13:40:16,199 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 13:40:16,199 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 13:40:16,200 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 13:40:16,200 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 13:40:16,204 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 13:40:16,220 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 13:40:16,220 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 13:40:16,220 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 13:40:16,226 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 305; bufvoid = 104857600
2016-02-16 13:40:16,226 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2016-02-16 13:40:16,235 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 13:40:16,238 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1819689952_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 13:40:16,253 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 13:40:16,254 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1819689952_0001_m_000000_0' done.
2016-02-16 13:40:16,254 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1819689952_0001_m_000000_0
2016-02-16 13:40:16,254 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 13:40:16,259 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 13:40:16,259 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1819689952_0001_r_000000_0
2016-02-16 13:40:16,267 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:40:16,268 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:40:16,272 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@45f0d31e
2016-02-16 13:40:16,285 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 13:40:16,292 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1819689952_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 13:40:16,338 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1819689952_0001_m_000000_0 decomp: 337 len: 341 to MEMORY
2016-02-16 13:40:16,349 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 337 bytes from map-output for attempt_local1819689952_0001_m_000000_0
2016-02-16 13:40:16,354 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 337, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->337
2016-02-16 13:40:16,356 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 13:40:16,358 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:40:16,359 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 13:40:16,367 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:40:16,368 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 13:40:16,369 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 337 bytes to disk to satisfy reduce memory limit
2016-02-16 13:40:16,369 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 341 bytes from disk
2016-02-16 13:40:16,370 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 13:40:16,371 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:40:16,371 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 13:40:16,372 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:40:16,383 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 13:40:16,389 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 13:40:16,399 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1819689952_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 13:40:16,785 INFO org.apache.hadoop.mapreduce.Job: Job job_local1819689952_0001 running in uber mode : false
2016-02-16 13:40:16,786 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 13:40:16,787 INFO org.apache.hadoop.mapreduce.Job: Job job_local1819689952_0001 failed with state FAILED due to: NA
2016-02-16 13:40:16,798 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263884
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=15
		Map output bytes=305
		Map output materialized bytes=341
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=341
		Reduce input records=0
		Reduce output records=0
		Spilled Records=15
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=38
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 13:41:43,928 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 13:41:44,624 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 13:41:44,627 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 13:41:45,548 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 13:41:45,562 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 13:41:45,593 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 13:41:45,686 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 13:41:45,995 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1683703481_0001
2016-02-16 13:41:46,613 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 13:41:46,614 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1683703481_0001
2016-02-16 13:41:46,620 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 13:41:46,641 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:41:46,647 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 13:41:46,823 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 13:41:46,829 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1683703481_0001_m_000000_0
2016-02-16 13:41:46,907 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:41:46,929 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:41:46,937 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 13:41:47,059 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 13:41:47,059 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 13:41:47,059 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 13:41:47,059 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 13:41:47,059 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 13:41:47,065 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 13:41:47,084 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 13:41:47,084 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 13:41:47,084 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 13:41:47,091 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 305; bufvoid = 104857600
2016-02-16 13:41:47,091 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600
2016-02-16 13:41:47,101 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 13:41:47,105 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1683703481_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 13:41:47,117 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 13:41:47,117 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1683703481_0001_m_000000_0' done.
2016-02-16 13:41:47,117 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1683703481_0001_m_000000_0
2016-02-16 13:41:47,117 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 13:41:47,122 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 13:41:47,122 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1683703481_0001_r_000000_0
2016-02-16 13:41:47,130 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:41:47,131 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:41:47,136 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@333481d2
2016-02-16 13:41:47,154 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 13:41:47,165 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1683703481_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 13:41:47,226 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1683703481_0001_m_000000_0 decomp: 337 len: 341 to MEMORY
2016-02-16 13:41:47,231 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 337 bytes from map-output for attempt_local1683703481_0001_m_000000_0
2016-02-16 13:41:47,234 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 337, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->337
2016-02-16 13:41:47,236 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 13:41:47,237 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:41:47,237 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 13:41:47,245 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:41:47,246 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 13:41:47,247 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 337 bytes to disk to satisfy reduce memory limit
2016-02-16 13:41:47,247 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 341 bytes from disk
2016-02-16 13:41:47,248 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 13:41:47,248 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:41:47,249 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 333 bytes
2016-02-16 13:41:47,249 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:41:47,257 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 13:41:47,271 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 13:41:47,274 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1683703481_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 13:41:47,618 INFO org.apache.hadoop.mapreduce.Job: Job job_local1683703481_0001 running in uber mode : false
2016-02-16 13:41:47,619 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 13:41:47,620 INFO org.apache.hadoop.mapreduce.Job: Job job_local1683703481_0001 failed with state FAILED due to: NA
2016-02-16 13:41:47,633 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263884
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=15
		Map output bytes=305
		Map output materialized bytes=341
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=341
		Reduce input records=0
		Reduce output records=0
		Spilled Records=15
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=46
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 13:46:46,333 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 13:46:46,993 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 13:46:46,997 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 13:46:47,732 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 13:46:47,735 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 13:46:47,753 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 13:46:47,802 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 13:46:48,111 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1053442601_0001
2016-02-16 13:46:48,720 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 13:46:48,722 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1053442601_0001
2016-02-16 13:46:48,724 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 13:46:48,742 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:46:48,755 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 13:46:48,933 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 13:46:48,934 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1053442601_0001_m_000000_0
2016-02-16 13:46:49,011 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:46:49,051 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:46:49,055 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 13:46:49,232 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 13:46:49,232 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 13:46:49,232 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 13:46:49,232 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 13:46:49,232 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 13:46:49,238 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 13:46:49,272 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 13:46:49,275 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 13:46:49,276 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 13:46:49,279 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 13:46:49,279 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 13:46:49,304 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 13:46:49,313 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1053442601_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 13:46:49,340 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 13:46:49,340 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1053442601_0001_m_000000_0' done.
2016-02-16 13:46:49,340 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1053442601_0001_m_000000_0
2016-02-16 13:46:49,343 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 13:46:49,348 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 13:46:49,348 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1053442601_0001_r_000000_0
2016-02-16 13:46:49,368 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:46:49,369 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:46:49,373 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@29367413
2016-02-16 13:46:49,406 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 13:46:49,420 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1053442601_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 13:46:49,526 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1053442601_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 13:46:49,537 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local1053442601_0001_m_000000_0
2016-02-16 13:46:49,544 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 13:46:49,547 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 13:46:49,548 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:46:49,550 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 13:46:49,564 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:46:49,564 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 13:46:49,569 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 13:46:49,570 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 13:46:49,571 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 13:46:49,573 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:46:49,575 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 13:46:49,575 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:46:49,594 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 13:46:49,606 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 13:46:49,614 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1053442601_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 13:46:49,735 INFO org.apache.hadoop.mapreduce.Job: Job job_local1053442601_0001 running in uber mode : false
2016-02-16 13:46:49,737 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 13:46:49,739 INFO org.apache.hadoop.mapreduce.Job: Job job_local1053442601_0001 failed with state FAILED due to: NA
2016-02-16 13:46:49,768 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=67
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 13:53:59,226 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 13:53:59,914 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 13:53:59,919 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 13:54:00,839 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 13:54:00,850 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 13:54:00,898 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 13:54:00,988 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 13:54:01,308 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local993710471_0001
2016-02-16 13:54:01,907 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 13:54:01,908 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local993710471_0001
2016-02-16 13:54:01,914 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 13:54:01,932 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:54:01,942 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 13:54:02,124 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 13:54:02,128 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local993710471_0001_m_000000_0
2016-02-16 13:54:02,199 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:54:02,232 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:54:02,238 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 13:54:02,340 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 13:54:02,340 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 13:54:02,340 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 13:54:02,340 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 13:54:02,340 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 13:54:02,345 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 13:54:02,361 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 13:54:02,361 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 13:54:02,362 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 13:54:02,368 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 13:54:02,368 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 13:54:02,377 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 13:54:02,380 INFO org.apache.hadoop.mapred.Task: Task:attempt_local993710471_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 13:54:02,390 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 13:54:02,391 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local993710471_0001_m_000000_0' done.
2016-02-16 13:54:02,391 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local993710471_0001_m_000000_0
2016-02-16 13:54:02,391 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 13:54:02,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 13:54:02,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local993710471_0001_r_000000_0
2016-02-16 13:54:02,403 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 13:54:02,403 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 13:54:02,406 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2315da09
2016-02-16 13:54:02,421 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 13:54:02,429 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local993710471_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 13:54:02,493 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local993710471_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 13:54:02,503 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local993710471_0001_m_000000_0
2016-02-16 13:54:02,504 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 13:54:02,506 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 13:54:02,507 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:54:02,509 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 13:54:02,517 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:54:02,517 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 13:54:02,519 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 13:54:02,519 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 13:54:02,520 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 13:54:02,520 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 13:54:02,521 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 13:54:02,522 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 13:54:02,529 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 13:54:02,537 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 13:54:02,540 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local993710471_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 13:54:02,911 INFO org.apache.hadoop.mapreduce.Job: Job job_local993710471_0001 running in uber mode : false
2016-02-16 13:54:02,913 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 13:54:02,914 INFO org.apache.hadoop.mapreduce.Job: Job job_local993710471_0001 failed with state FAILED due to: NA
2016-02-16 13:54:02,926 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 14:20:08,476 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:20:09,230 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:20:09,236 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:20:09,888 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:20:09,890 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:20:09,909 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:20:09,957 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:20:10,256 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1289922490_0001
2016-02-16 14:20:10,832 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:20:10,834 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1289922490_0001
2016-02-16 14:20:10,837 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:20:10,855 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:20:10,861 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:20:11,046 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:20:11,047 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1289922490_0001_m_000000_0
2016-02-16 14:20:11,116 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:20:11,158 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:20:11,163 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:20:11,350 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:20:11,350 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:20:11,350 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:20:11,350 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:20:11,351 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:20:11,367 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:20:11,411 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 14:20:11,411 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:20:11,411 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 14:20:11,418 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 14:20:11,419 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 14:20:11,450 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 14:20:11,468 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1289922490_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 14:20:11,487 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 14:20:11,491 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1289922490_0001_m_000000_0' done.
2016-02-16 14:20:11,491 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1289922490_0001_m_000000_0
2016-02-16 14:20:11,491 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:20:11,501 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 14:20:11,502 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1289922490_0001_r_000000_0
2016-02-16 14:20:11,525 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:20:11,526 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:20:11,533 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@66dafb3a
2016-02-16 14:20:11,575 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 14:20:11,589 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1289922490_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 14:20:11,699 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1289922490_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 14:20:11,714 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local1289922490_0001_m_000000_0
2016-02-16 14:20:11,716 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 14:20:11,721 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 14:20:11,722 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:20:11,728 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 14:20:11,744 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:20:11,745 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:20:11,756 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 14:20:11,761 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 14:20:11,763 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 14:20:11,763 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:20:11,763 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:20:11,764 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:20:11,781 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 14:20:11,794 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 14:20:11,796 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1289922490_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 14:20:11,837 INFO org.apache.hadoop.mapreduce.Job: Job job_local1289922490_0001 running in uber mode : false
2016-02-16 14:20:11,838 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 14:20:11,847 INFO org.apache.hadoop.mapreduce.Job: Job job_local1289922490_0001 failed with state FAILED due to: NA
2016-02-16 14:20:11,891 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=77
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 14:29:22,968 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:29:23,691 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:29:23,701 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:29:24,609 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:29:24,620 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:29:24,655 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:29:24,744 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:29:25,053 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local873306475_0001
2016-02-16 14:29:25,737 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:29:25,740 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local873306475_0001
2016-02-16 14:29:25,753 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:29:25,781 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:29:25,786 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:29:26,001 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:29:26,004 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local873306475_0001_m_000000_0
2016-02-16 14:29:26,065 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:29:26,093 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:29:26,097 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:29:26,201 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:29:26,202 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:29:26,202 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:29:26,202 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:29:26,202 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:29:26,207 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:29:26,223 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 14:29:26,223 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:29:26,223 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 14:29:26,229 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 14:29:26,229 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 14:29:26,238 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 14:29:26,242 INFO org.apache.hadoop.mapred.Task: Task:attempt_local873306475_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 14:29:26,251 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 14:29:26,252 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local873306475_0001_m_000000_0' done.
2016-02-16 14:29:26,252 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local873306475_0001_m_000000_0
2016-02-16 14:29:26,252 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:29:26,256 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 14:29:26,257 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local873306475_0001_r_000000_0
2016-02-16 14:29:26,264 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:29:26,265 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:29:26,268 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2315da09
2016-02-16 14:29:26,294 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 14:29:26,301 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local873306475_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 14:29:26,346 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local873306475_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 14:29:26,351 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local873306475_0001_m_000000_0
2016-02-16 14:29:26,359 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 14:29:26,365 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 14:29:26,367 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:29:26,368 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 14:29:26,374 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:29:26,374 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:29:26,375 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 14:29:26,376 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 14:29:26,377 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 14:29:26,377 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:29:26,378 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:29:26,380 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:29:26,386 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 14:29:26,392 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 14:29:26,395 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local873306475_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 14:29:26,763 INFO org.apache.hadoop.mapreduce.Job: Job job_local873306475_0001 running in uber mode : false
2016-02-16 14:29:26,764 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 14:29:26,765 INFO org.apache.hadoop.mapreduce.Job: Job job_local873306475_0001 failed with state FAILED due to: NA
2016-02-16 14:29:26,777 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=31
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 14:30:09,023 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:30:09,692 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:30:09,697 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:30:10,363 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:30:10,366 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:30:10,383 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:30:10,434 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:30:10,771 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local821287301_0001
2016-02-16 14:30:11,367 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:30:11,374 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local821287301_0001
2016-02-16 14:30:11,378 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:30:11,394 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:30:11,403 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:30:11,583 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:30:11,584 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local821287301_0001_m_000000_0
2016-02-16 14:30:11,634 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:30:11,657 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:30:11,661 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:30:11,757 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:30:11,763 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:30:11,763 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:30:11,763 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:30:11,763 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:30:11,768 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:30:11,785 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 14:30:11,785 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:30:11,785 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 14:30:11,791 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 14:30:11,791 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 14:30:11,802 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 14:30:11,806 INFO org.apache.hadoop.mapred.Task: Task:attempt_local821287301_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 14:30:11,814 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 14:30:11,815 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local821287301_0001_m_000000_0' done.
2016-02-16 14:30:11,815 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local821287301_0001_m_000000_0
2016-02-16 14:30:11,815 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:30:11,820 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 14:30:11,820 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local821287301_0001_r_000000_0
2016-02-16 14:30:11,829 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:30:11,829 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:30:11,837 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2c91a704
2016-02-16 14:30:11,850 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 14:30:11,857 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local821287301_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 14:30:11,956 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local821287301_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 14:30:11,969 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local821287301_0001_m_000000_0
2016-02-16 14:30:11,971 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 14:30:11,975 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 14:30:11,976 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:30:11,977 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 14:30:11,991 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:30:11,991 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:30:11,994 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 14:30:11,995 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 14:30:11,996 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 14:30:11,999 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:30:12,000 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:30:12,000 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:30:12,016 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 14:30:12,026 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 14:30:12,029 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local821287301_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 14:30:12,376 INFO org.apache.hadoop.mapreduce.Job: Job job_local821287301_0001 running in uber mode : false
2016-02-16 14:30:12,377 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 14:30:12,383 INFO org.apache.hadoop.mapreduce.Job: Job job_local821287301_0001 failed with state FAILED due to: NA
2016-02-16 14:30:12,414 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=38
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 14:34:18,363 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:34:19,147 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:34:19,153 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:34:19,910 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:34:19,921 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:34:19,945 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:34:20,021 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:34:20,335 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local2090287649_0001
2016-02-16 14:34:20,990 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:34:20,990 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local2090287649_0001
2016-02-16 14:34:20,995 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:34:21,010 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:34:21,021 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:34:21,218 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:34:21,219 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2090287649_0001_m_000000_0
2016-02-16 14:34:21,299 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:34:21,338 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:34:21,351 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:34:21,515 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:34:21,516 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:34:21,516 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:34:21,516 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:34:21,516 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:34:21,527 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:34:21,551 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:34:21,568 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:34:21,570 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local2090287649_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:40)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 14:34:22,000 INFO org.apache.hadoop.mapreduce.Job: Job job_local2090287649_0001 running in uber mode : false
2016-02-16 14:34:22,002 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 14:34:22,008 INFO org.apache.hadoop.mapreduce.Job: Job job_local2090287649_0001 failed with state FAILED due to: NA
2016-02-16 14:34:22,022 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 14:35:51,000 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:35:51,735 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:35:51,737 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:35:52,712 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:35:52,723 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:35:52,763 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:35:52,844 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:35:53,193 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1541851522_0001
2016-02-16 14:35:53,781 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:35:53,783 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1541851522_0001
2016-02-16 14:35:53,786 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:35:53,805 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:35:53,815 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:35:54,001 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:35:54,004 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1541851522_0001_m_000000_0
2016-02-16 14:35:54,084 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:35:54,111 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:35:54,118 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:35:54,218 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:35:54,219 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:35:54,220 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:35:54,220 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:35:54,220 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:35:54,226 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:35:54,238 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:35:54,245 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:35:54,246 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1541851522_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:40)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 14:35:54,785 INFO org.apache.hadoop.mapreduce.Job: Job job_local1541851522_0001 running in uber mode : false
2016-02-16 14:35:54,786 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 14:35:54,788 INFO org.apache.hadoop.mapreduce.Job: Job job_local1541851522_0001 failed with state FAILED due to: NA
2016-02-16 14:35:54,794 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 14:37:08,971 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:37:09,691 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:37:09,695 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:37:10,633 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:37:10,646 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:37:10,681 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:37:10,745 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:37:11,104 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1038706194_0001
2016-02-16 14:37:11,693 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:37:11,695 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1038706194_0001
2016-02-16 14:37:11,697 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:37:11,723 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:37:11,732 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:37:11,918 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:37:11,919 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1038706194_0001_m_000000_0
2016-02-16 14:37:11,993 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:37:12,009 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:37:12,013 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:37:12,116 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:37:12,117 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:37:12,117 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:37:12,118 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:37:12,118 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:37:12,121 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:37:12,132 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:37:12,139 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:37:12,141 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1038706194_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:40)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 14:37:12,705 INFO org.apache.hadoop.mapreduce.Job: Job job_local1038706194_0001 running in uber mode : false
2016-02-16 14:37:12,707 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 14:37:12,708 INFO org.apache.hadoop.mapreduce.Job: Job job_local1038706194_0001 failed with state FAILED due to: NA
2016-02-16 14:37:12,715 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 14:37:48,417 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:37:49,109 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:37:49,114 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:37:50,077 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:37:50,090 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:37:50,136 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:37:50,210 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:37:50,515 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1342504665_0001
2016-02-16 14:37:51,165 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:37:51,168 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1342504665_0001
2016-02-16 14:37:51,178 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:37:51,195 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:37:51,203 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:37:51,401 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:37:51,402 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1342504665_0001_m_000000_0
2016-02-16 14:37:51,464 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:37:51,482 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:37:51,486 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:37:51,581 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:37:51,586 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:37:51,586 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:37:51,586 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:37:51,586 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:37:51,591 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:37:51,601 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:37:51,609 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:37:51,611 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1342504665_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:40)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 14:37:52,172 INFO org.apache.hadoop.mapreduce.Job: Job job_local1342504665_0001 running in uber mode : false
2016-02-16 14:37:52,174 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 14:37:52,177 INFO org.apache.hadoop.mapreduce.Job: Job job_local1342504665_0001 failed with state FAILED due to: NA
2016-02-16 14:37:52,183 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 14:39:45,460 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:39:46,193 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:39:46,195 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:39:47,026 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:39:47,037 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:39:47,074 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:39:47,162 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:39:47,465 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local734743292_0001
2016-02-16 14:39:48,076 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:39:48,081 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local734743292_0001
2016-02-16 14:39:48,088 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:39:48,106 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:39:48,117 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:39:48,303 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:39:48,304 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local734743292_0001_m_000000_0
2016-02-16 14:39:48,370 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:39:48,398 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:39:48,403 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:39:48,502 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:39:48,506 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:39:48,506 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:39:48,507 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:39:48,507 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:39:48,512 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:39:48,523 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:39:48,530 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:39:48,531 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local734743292_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:40)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 14:39:49,083 INFO org.apache.hadoop.mapreduce.Job: Job job_local734743292_0001 running in uber mode : false
2016-02-16 14:39:49,084 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 14:39:49,086 INFO org.apache.hadoop.mapreduce.Job: Job job_local734743292_0001 failed with state FAILED due to: NA
2016-02-16 14:39:49,092 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 14:40:53,385 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:40:54,072 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:40:54,076 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:40:54,161 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/Desktop/hw3_output already exists
2016-02-16 14:41:02,462 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:41:03,113 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:41:03,117 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:41:03,782 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:41:03,785 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:41:03,803 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:41:03,847 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:41:04,142 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1748126567_0001
2016-02-16 14:41:04,747 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:41:04,749 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1748126567_0001
2016-02-16 14:41:04,753 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:41:04,776 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:41:04,791 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:41:04,971 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:41:04,973 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1748126567_0001_m_000000_0
2016-02-16 14:41:05,020 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:41:05,036 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:41:05,041 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:41:05,145 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:41:05,145 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:41:05,145 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:41:05,145 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:41:05,145 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:41:05,150 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:41:05,159 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:41:05,167 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:41:05,170 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1748126567_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:40)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 14:41:05,751 INFO org.apache.hadoop.mapreduce.Job: Job job_local1748126567_0001 running in uber mode : false
2016-02-16 14:41:05,753 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 14:41:05,756 INFO org.apache.hadoop.mapreduce.Job: Job job_local1748126567_0001 failed with state FAILED due to: NA
2016-02-16 14:41:05,778 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 14:41:56,836 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:41:57,859 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:41:57,866 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:41:58,807 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:41:58,821 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:41:58,857 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:41:58,940 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:41:59,240 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local539754418_0001
2016-02-16 14:41:59,874 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:41:59,875 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local539754418_0001
2016-02-16 14:41:59,887 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:41:59,899 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:41:59,903 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:42:00,090 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:42:00,092 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local539754418_0001_m_000000_0
2016-02-16 14:42:00,160 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:42:00,185 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:42:00,188 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:42:00,287 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:42:00,288 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:42:00,288 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:42:00,288 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:42:00,288 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:42:00,292 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:42:00,302 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:42:00,309 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:42:00,311 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local539754418_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:40)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 14:42:00,879 INFO org.apache.hadoop.mapreduce.Job: Job job_local539754418_0001 running in uber mode : false
2016-02-16 14:42:00,881 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 14:42:00,883 INFO org.apache.hadoop.mapreduce.Job: Job job_local539754418_0001 failed with state FAILED due to: NA
2016-02-16 14:42:00,890 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 14:42:45,830 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:42:46,511 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:42:46,512 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:42:47,518 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:42:47,533 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:42:47,568 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:42:47,644 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:42:47,953 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1095871109_0001
2016-02-16 14:42:48,524 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:42:48,525 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1095871109_0001
2016-02-16 14:42:48,530 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:42:48,549 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:42:48,555 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:42:48,733 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:42:48,735 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1095871109_0001_m_000000_0
2016-02-16 14:42:48,807 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:42:48,825 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:42:48,829 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:42:48,930 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:42:48,930 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:42:48,930 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:42:48,930 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:42:48,930 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:42:48,935 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:42:48,952 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 14:42:48,952 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:42:48,953 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 14:42:48,959 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 14:42:48,959 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 14:42:48,970 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 14:42:48,974 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1095871109_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 14:42:48,986 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 14:42:48,986 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1095871109_0001_m_000000_0' done.
2016-02-16 14:42:48,986 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1095871109_0001_m_000000_0
2016-02-16 14:42:48,986 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:42:48,991 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 14:42:48,991 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1095871109_0001_r_000000_0
2016-02-16 14:42:48,999 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:42:49,000 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:42:49,006 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@16e2a4c8
2016-02-16 14:42:49,022 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 14:42:49,030 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1095871109_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 14:42:49,097 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1095871109_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 14:42:49,103 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local1095871109_0001_m_000000_0
2016-02-16 14:42:49,105 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 14:42:49,107 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 14:42:49,108 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:42:49,109 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 14:42:49,118 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:42:49,119 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:42:49,121 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 14:42:49,121 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 14:42:49,122 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 14:42:49,123 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:42:49,123 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:42:49,124 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:42:49,132 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 14:42:49,139 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 14:42:49,143 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1095871109_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 14:42:49,528 INFO org.apache.hadoop.mapreduce.Job: Job job_local1095871109_0001 running in uber mode : false
2016-02-16 14:42:49,529 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 14:42:49,530 INFO org.apache.hadoop.mapreduce.Job: Job job_local1095871109_0001 failed with state FAILED due to: NA
2016-02-16 14:42:49,541 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 14:44:06,829 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:44:07,520 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:44:07,525 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:44:08,528 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:44:08,543 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:44:08,592 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:44:08,688 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:44:09,078 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1025713946_0001
2016-02-16 14:44:09,686 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:44:09,688 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1025713946_0001
2016-02-16 14:44:09,692 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:44:09,709 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:44:09,715 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:44:09,900 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:44:09,901 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1025713946_0001_m_000000_0
2016-02-16 14:44:09,965 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:44:09,983 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:44:09,986 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:44:10,083 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:44:10,089 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:44:10,089 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:44:10,089 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:44:10,089 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:44:10,093 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:44:10,111 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 14:44:10,112 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:44:10,112 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 14:44:10,118 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 14:44:10,119 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 14:44:10,128 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 14:44:10,133 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1025713946_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 14:44:10,149 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 14:44:10,150 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1025713946_0001_m_000000_0' done.
2016-02-16 14:44:10,150 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1025713946_0001_m_000000_0
2016-02-16 14:44:10,150 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:44:10,155 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 14:44:10,155 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1025713946_0001_r_000000_0
2016-02-16 14:44:10,161 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:44:10,162 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:44:10,166 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3ccf7a24
2016-02-16 14:44:10,179 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 14:44:10,184 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1025713946_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 14:44:10,228 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1025713946_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 14:44:10,246 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local1025713946_0001_m_000000_0
2016-02-16 14:44:10,248 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 14:44:10,250 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 14:44:10,251 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:44:10,251 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 14:44:10,258 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:44:10,259 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:44:10,260 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 14:44:10,260 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 14:44:10,261 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 14:44:10,262 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:44:10,262 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:44:10,263 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:44:10,271 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 14:44:10,277 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 14:44:10,280 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1025713946_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 14:44:10,696 INFO org.apache.hadoop.mapreduce.Job: Job job_local1025713946_0001 running in uber mode : false
2016-02-16 14:44:10,697 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 14:44:10,699 INFO org.apache.hadoop.mapreduce.Job: Job job_local1025713946_0001 failed with state FAILED due to: NA
2016-02-16 14:44:10,710 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=34
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 14:47:07,901 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:47:08,624 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:47:08,629 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:47:09,267 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:47:09,270 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:47:09,290 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:47:09,352 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:47:09,697 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local935035755_0001
2016-02-16 14:47:10,302 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:47:10,304 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local935035755_0001
2016-02-16 14:47:10,307 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:47:10,335 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:47:10,338 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:47:10,527 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:47:10,529 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local935035755_0001_m_000000_0
2016-02-16 14:47:10,604 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:47:10,655 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:47:10,664 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:47:10,826 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:47:10,826 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:47:10,826 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:47:10,826 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:47:10,826 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:47:10,836 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:47:10,868 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 14:47:10,872 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:47:10,872 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 14:47:10,875 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 14:47:10,876 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 14:47:10,898 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 14:47:10,906 INFO org.apache.hadoop.mapred.Task: Task:attempt_local935035755_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 14:47:10,924 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 14:47:10,926 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local935035755_0001_m_000000_0' done.
2016-02-16 14:47:10,926 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local935035755_0001_m_000000_0
2016-02-16 14:47:10,933 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:47:10,940 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 14:47:10,941 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local935035755_0001_r_000000_0
2016-02-16 14:47:10,957 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:47:10,958 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:47:10,963 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15796446
2016-02-16 14:47:11,010 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 14:47:11,024 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local935035755_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 14:47:11,129 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local935035755_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 14:47:11,139 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local935035755_0001_m_000000_0
2016-02-16 14:47:11,142 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 14:47:11,146 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 14:47:11,147 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:47:11,147 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 14:47:11,162 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:47:11,163 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:47:11,166 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 14:47:11,167 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 14:47:11,168 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 14:47:11,168 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:47:11,169 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:47:11,171 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:47:11,185 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 14:47:11,199 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 14:47:11,207 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local935035755_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 14:47:11,314 INFO org.apache.hadoop.mapreduce.Job: Job job_local935035755_0001 running in uber mode : false
2016-02-16 14:47:11,315 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 14:47:11,317 INFO org.apache.hadoop.mapreduce.Job: Job job_local935035755_0001 failed with state FAILED due to: NA
2016-02-16 14:47:11,344 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=66
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 14:51:10,237 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:51:10,939 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:51:10,945 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:51:11,848 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:51:11,863 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:51:11,901 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:51:11,986 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:51:12,297 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local2082860124_0001
2016-02-16 14:51:12,906 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:51:12,907 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local2082860124_0001
2016-02-16 14:51:12,916 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:51:12,936 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:51:12,938 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:51:13,131 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:51:13,134 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2082860124_0001_m_000000_0
2016-02-16 14:51:13,204 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:51:13,226 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:51:13,230 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:51:13,328 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:51:13,332 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:51:13,334 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:51:13,334 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:51:13,335 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:51:13,338 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:51:13,356 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 14:51:13,356 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:51:13,356 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 14:51:13,362 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 14:51:13,362 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 14:51:13,373 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 14:51:13,377 INFO org.apache.hadoop.mapred.Task: Task:attempt_local2082860124_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 14:51:13,389 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 14:51:13,390 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local2082860124_0001_m_000000_0' done.
2016-02-16 14:51:13,390 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local2082860124_0001_m_000000_0
2016-02-16 14:51:13,391 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:51:13,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 14:51:13,395 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local2082860124_0001_r_000000_0
2016-02-16 14:51:13,402 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:51:13,402 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:51:13,406 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@16e2a4c8
2016-02-16 14:51:13,423 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 14:51:13,428 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local2082860124_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 14:51:13,486 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2082860124_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 14:51:13,501 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local2082860124_0001_m_000000_0
2016-02-16 14:51:13,503 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 14:51:13,505 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 14:51:13,507 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:51:13,507 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 14:51:13,515 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:51:13,516 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:51:13,517 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 14:51:13,517 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 14:51:13,518 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 14:51:13,519 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:51:13,519 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:51:13,520 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:51:13,527 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 14:51:13,534 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 14:51:13,538 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local2082860124_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 14:51:13,922 INFO org.apache.hadoop.mapreduce.Job: Job job_local2082860124_0001 running in uber mode : false
2016-02-16 14:51:13,942 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 14:51:13,945 INFO org.apache.hadoop.mapreduce.Job: Job job_local2082860124_0001 failed with state FAILED due to: NA
2016-02-16 14:51:13,957 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 14:59:21,756 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 14:59:22,406 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 14:59:22,411 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 14:59:23,099 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 14:59:23,103 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 14:59:23,114 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 14:59:23,168 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 14:59:23,532 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local420194222_0001
2016-02-16 14:59:24,150 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 14:59:24,151 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local420194222_0001
2016-02-16 14:59:24,157 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 14:59:24,181 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:59:24,188 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 14:59:24,360 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 14:59:24,361 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local420194222_0001_m_000000_0
2016-02-16 14:59:24,430 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:59:24,476 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:59:24,485 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 14:59:24,661 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 14:59:24,661 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 14:59:24,661 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 14:59:24,662 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 14:59:24,662 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 14:59:24,674 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 14:59:24,715 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 14:59:24,716 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 14:59:24,716 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 14:59:24,723 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 14:59:24,723 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 14:59:24,749 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 14:59:24,759 INFO org.apache.hadoop.mapred.Task: Task:attempt_local420194222_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 14:59:24,786 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 14:59:24,791 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local420194222_0001_m_000000_0' done.
2016-02-16 14:59:24,791 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local420194222_0001_m_000000_0
2016-02-16 14:59:24,791 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 14:59:24,801 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 14:59:24,802 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local420194222_0001_r_000000_0
2016-02-16 14:59:24,830 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 14:59:24,831 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 14:59:24,847 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@e6c0e78
2016-02-16 14:59:24,890 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 14:59:24,907 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local420194222_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 14:59:25,033 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local420194222_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 14:59:25,045 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local420194222_0001_m_000000_0
2016-02-16 14:59:25,055 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 14:59:25,057 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 14:59:25,057 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:59:25,058 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 14:59:25,073 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:59:25,076 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:59:25,080 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 14:59:25,081 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 14:59:25,083 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 14:59:25,083 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 14:59:25,090 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 14:59:25,092 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 14:59:25,107 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 14:59:25,120 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 14:59:25,124 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local420194222_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 14:59:25,156 INFO org.apache.hadoop.mapreduce.Job: Job job_local420194222_0001 running in uber mode : false
2016-02-16 14:59:25,157 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 14:59:25,164 INFO org.apache.hadoop.mapreduce.Job: Job job_local420194222_0001 failed with state FAILED due to: NA
2016-02-16 14:59:25,209 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=65
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 15:00:33,231 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 15:00:33,901 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 15:00:33,907 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 15:00:34,575 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 15:00:34,578 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 15:00:34,596 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 15:00:34,648 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 15:00:34,953 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1492614440_0001
2016-02-16 15:00:35,546 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 15:00:35,550 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 15:00:35,550 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1492614440_0001
2016-02-16 15:00:35,575 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:00:35,579 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 15:00:35,765 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 15:00:35,766 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1492614440_0001_m_000000_0
2016-02-16 15:00:35,853 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:00:35,894 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:00:35,905 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 15:00:36,104 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 15:00:36,104 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 15:00:36,104 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 15:00:36,104 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 15:00:36,104 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 15:00:36,119 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 15:00:36,139 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 15:00:36,159 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 15:00:36,161 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1492614440_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.IntWritable, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.IntWritable, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:40)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 15:00:36,560 INFO org.apache.hadoop.mapreduce.Job: Job job_local1492614440_0001 running in uber mode : false
2016-02-16 15:00:36,563 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 15:00:36,564 INFO org.apache.hadoop.mapreduce.Job: Job job_local1492614440_0001 failed with state FAILED due to: NA
2016-02-16 15:00:36,579 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 15:01:19,890 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 15:01:20,589 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 15:01:20,590 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 15:01:21,228 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 15:01:21,231 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 15:01:21,247 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 15:01:21,294 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 15:01:21,595 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local198153716_0001
2016-02-16 15:01:22,232 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 15:01:22,234 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local198153716_0001
2016-02-16 15:01:22,237 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 15:01:22,257 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:01:22,267 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 15:01:22,441 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 15:01:22,442 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local198153716_0001_m_000000_0
2016-02-16 15:01:22,507 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:01:22,528 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:01:22,532 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 15:01:22,629 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 15:01:22,634 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 15:01:22,634 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 15:01:22,634 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 15:01:22,634 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 15:01:22,638 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 15:01:22,655 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 15:01:22,656 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 15:01:22,656 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 15:01:22,661 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 15:01:22,661 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 15:01:22,672 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 15:01:22,675 INFO org.apache.hadoop.mapred.Task: Task:attempt_local198153716_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 15:01:22,684 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 15:01:22,684 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local198153716_0001_m_000000_0' done.
2016-02-16 15:01:22,684 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local198153716_0001_m_000000_0
2016-02-16 15:01:22,684 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 15:01:22,688 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 15:01:22,688 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local198153716_0001_r_000000_0
2016-02-16 15:01:22,696 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:01:22,696 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:01:22,703 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@70647819
2016-02-16 15:01:22,725 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 15:01:22,735 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local198153716_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 15:01:22,782 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local198153716_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 15:01:22,787 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local198153716_0001_m_000000_0
2016-02-16 15:01:22,789 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 15:01:22,790 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 15:01:22,792 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:01:22,792 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 15:01:22,799 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:01:22,799 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 15:01:22,801 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 15:01:22,802 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 15:01:22,802 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 15:01:22,803 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:01:22,803 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 15:01:22,804 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:01:22,810 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 15:01:22,815 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 15:01:22,818 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local198153716_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 15:01:23,235 INFO org.apache.hadoop.mapreduce.Job: Job job_local198153716_0001 running in uber mode : false
2016-02-16 15:01:23,236 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 15:01:23,238 INFO org.apache.hadoop.mapreduce.Job: Job job_local198153716_0001 failed with state FAILED due to: NA
2016-02-16 15:01:23,249 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=33
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 15:10:06,485 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 15:10:07,182 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 15:10:07,187 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 15:10:08,159 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 15:10:08,171 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 15:10:08,226 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 15:10:08,293 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 15:10:08,591 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1950003663_0001
2016-02-16 15:10:09,208 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 15:10:09,210 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1950003663_0001
2016-02-16 15:10:09,219 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 15:10:09,240 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:10:09,244 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 15:10:09,462 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 15:10:09,463 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1950003663_0001_m_000000_0
2016-02-16 15:10:09,533 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:10:09,551 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:10:09,557 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 15:10:09,653 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 15:10:09,656 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 15:10:09,656 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 15:10:09,656 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 15:10:09,657 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 15:10:09,663 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 15:10:09,668 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 15:10:09,676 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 15:10:09,677 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1950003663_0001
java.lang.Exception: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.Text, received org.apache.hadoop.io.LongWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1073)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at org.apache.hadoop.mapreduce.Mapper.map(Mapper.java:124)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 15:10:10,215 INFO org.apache.hadoop.mapreduce.Job: Job job_local1950003663_0001 running in uber mode : false
2016-02-16 15:10:10,219 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 15:10:10,223 INFO org.apache.hadoop.mapreduce.Job: Job job_local1950003663_0001 failed with state FAILED due to: NA
2016-02-16 15:10:10,233 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 15:15:00,758 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 15:15:01,415 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 15:15:01,418 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 15:15:02,067 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 15:15:02,070 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 15:15:02,089 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 15:15:02,149 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 15:15:02,448 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local622108281_0001
2016-02-16 15:15:03,026 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 15:15:03,031 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local622108281_0001
2016-02-16 15:15:03,036 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 15:15:03,052 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:15:03,057 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 15:15:03,239 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 15:15:03,240 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local622108281_0001_m_000000_0
2016-02-16 15:15:03,310 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:15:03,362 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:15:03,367 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 15:15:03,548 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 15:15:03,554 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 15:15:03,555 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 15:15:03,555 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 15:15:03,555 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 15:15:03,565 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 15:15:03,598 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 15:15:03,601 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 15:15:03,601 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 15:15:03,605 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 15:15:03,605 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 15:15:03,629 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 15:15:03,636 INFO org.apache.hadoop.mapred.Task: Task:attempt_local622108281_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 15:15:03,662 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 15:15:03,665 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local622108281_0001_m_000000_0' done.
2016-02-16 15:15:03,665 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local622108281_0001_m_000000_0
2016-02-16 15:15:03,666 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 15:15:03,675 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 15:15:03,676 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local622108281_0001_r_000000_0
2016-02-16 15:15:03,697 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:15:03,698 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:15:03,707 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2888dcd1
2016-02-16 15:15:03,743 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 15:15:03,762 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local622108281_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 15:15:03,861 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local622108281_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 15:15:03,874 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local622108281_0001_m_000000_0
2016-02-16 15:15:03,877 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 15:15:03,883 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 15:15:03,885 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:15:03,885 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 15:15:03,896 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:15:03,897 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 15:15:03,900 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 15:15:03,901 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 15:15:03,905 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 15:15:03,905 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:15:03,906 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 15:15:03,907 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:15:03,925 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 15:15:03,932 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 15:15:03,936 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local622108281_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 15:15:04,035 INFO org.apache.hadoop.mapreduce.Job: Job job_local622108281_0001 running in uber mode : false
2016-02-16 15:15:04,041 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 15:15:04,047 INFO org.apache.hadoop.mapreduce.Job: Job job_local622108281_0001 failed with state FAILED due to: NA
2016-02-16 15:15:04,087 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=67
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 15:16:41,503 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 15:16:42,328 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 15:16:42,331 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 15:16:43,324 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 15:16:43,334 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 15:16:43,373 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 15:16:43,462 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 15:16:43,773 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1878836588_0001
2016-02-16 15:16:44,423 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 15:16:44,425 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1878836588_0001
2016-02-16 15:16:44,437 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 15:16:44,466 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:16:44,484 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 15:16:44,678 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 15:16:44,679 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1878836588_0001_m_000000_0
2016-02-16 15:16:44,763 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:16:44,789 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:16:44,794 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 15:16:44,911 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 15:16:44,915 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 15:16:44,915 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 15:16:44,915 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 15:16:44,915 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 15:16:44,920 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 15:16:44,931 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 15:16:44,939 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 15:16:44,941 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1878836588_0001
java.lang.Exception: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.IntWritable, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Type mismatch in value from map: expected org.apache.hadoop.io.IntWritable, received org.apache.hadoop.io.ArrayWritable
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1078)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at PageRankMapper.map(PageRankMapper.java:40)
	at PageRankMapper.map(PageRankMapper.java:1)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:145)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 15:16:45,441 INFO org.apache.hadoop.mapreduce.Job: Job job_local1878836588_0001 running in uber mode : false
2016-02-16 15:16:45,442 INFO org.apache.hadoop.mapreduce.Job:  map 0% reduce 0%
2016-02-16 15:16:45,445 INFO org.apache.hadoop.mapreduce.Job: Job job_local1878836588_0001 failed with state FAILED due to: NA
2016-02-16 15:16:45,451 INFO org.apache.hadoop.mapreduce.Job: Counters: 0
2016-02-16 15:17:34,051 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 15:17:34,740 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 15:17:34,746 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 15:17:35,696 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 15:17:35,712 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 15:17:35,747 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 15:17:35,824 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 15:17:36,123 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1343490120_0001
2016-02-16 15:17:36,725 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 15:17:36,726 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1343490120_0001
2016-02-16 15:17:36,728 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 15:17:36,743 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:17:36,749 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 15:17:36,939 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 15:17:36,943 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1343490120_0001_m_000000_0
2016-02-16 15:17:37,022 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:17:37,037 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:17:37,046 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 15:17:37,155 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 15:17:37,156 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 15:17:37,156 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 15:17:37,156 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 15:17:37,156 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 15:17:37,160 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 15:17:37,177 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 15:17:37,178 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 15:17:37,178 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 15:17:37,183 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 15:17:37,184 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 15:17:37,192 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 15:17:37,196 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1343490120_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 15:17:37,209 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 15:17:37,209 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1343490120_0001_m_000000_0' done.
2016-02-16 15:17:37,209 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1343490120_0001_m_000000_0
2016-02-16 15:17:37,210 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 15:17:37,213 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 15:17:37,213 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1343490120_0001_r_000000_0
2016-02-16 15:17:37,221 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 15:17:37,221 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 15:17:37,226 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f9d96dd
2016-02-16 15:17:37,239 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 15:17:37,247 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1343490120_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 15:17:37,295 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1343490120_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 15:17:37,300 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local1343490120_0001_m_000000_0
2016-02-16 15:17:37,302 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 15:17:37,303 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 15:17:37,305 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:17:37,305 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 15:17:37,319 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:17:37,320 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 15:17:37,323 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 15:17:37,324 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 15:17:37,325 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 15:17:37,325 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 15:17:37,325 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 15:17:37,326 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 15:17:37,334 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 15:17:37,341 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 15:17:37,344 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1343490120_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 15:17:37,731 INFO org.apache.hadoop.mapreduce.Job: Job job_local1343490120_0001 running in uber mode : false
2016-02-16 15:17:37,733 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 15:17:37,734 INFO org.apache.hadoop.mapreduce.Job: Job job_local1343490120_0001 failed with state FAILED due to: NA
2016-02-16 15:17:37,744 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263977
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=42
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 19:56:08,639 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 19:56:09,554 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 19:56:09,559 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 19:56:10,253 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 19:56:10,256 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 19:56:10,273 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 19:56:10,336 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 19:56:10,828 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local868320427_0001
2016-02-16 19:56:11,728 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 19:56:11,729 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local868320427_0001
2016-02-16 19:56:11,739 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 19:56:11,766 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 19:56:11,774 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 19:56:11,971 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 19:56:11,972 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local868320427_0001_m_000000_0
2016-02-16 19:56:12,020 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 19:56:12,054 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 19:56:12,059 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 19:56:12,177 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 19:56:12,178 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 19:56:12,178 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 19:56:12,178 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 19:56:12,178 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 19:56:12,183 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 19:56:12,200 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 19:56:12,201 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 19:56:12,201 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 19:56:12,205 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 386; bufvoid = 104857600
2016-02-16 19:56:12,205 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 19:56:12,220 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 19:56:12,225 INFO org.apache.hadoop.mapred.Task: Task:attempt_local868320427_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 19:56:12,239 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 19:56:12,239 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local868320427_0001_m_000000_0' done.
2016-02-16 19:56:12,239 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local868320427_0001_m_000000_0
2016-02-16 19:56:12,239 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 19:56:12,244 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 19:56:12,244 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local868320427_0001_r_000000_0
2016-02-16 19:56:12,252 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 19:56:12,253 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 19:56:12,257 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42f599c6
2016-02-16 19:56:12,279 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 19:56:12,285 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local868320427_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 19:56:12,385 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local868320427_0001_m_000000_0 decomp: 430 len: 434 to MEMORY
2016-02-16 19:56:12,400 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 430 bytes from map-output for attempt_local868320427_0001_m_000000_0
2016-02-16 19:56:12,407 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 430, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->430
2016-02-16 19:56:12,413 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 19:56:12,414 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 19:56:12,415 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 19:56:12,427 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 19:56:12,430 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 19:56:12,432 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 430 bytes to disk to satisfy reduce memory limit
2016-02-16 19:56:12,432 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 434 bytes from disk
2016-02-16 19:56:12,438 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 19:56:12,444 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 19:56:12,445 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 426 bytes
2016-02-16 19:56:12,448 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 19:56:12,465 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 19:56:12,479 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 19:56:12,483 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local868320427_0001
java.lang.Exception: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.RuntimeException: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:131)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:66)
	at org.apache.hadoop.io.serializer.WritableSerialization$WritableDeserializer.deserialize(WritableSerialization.java:42)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:146)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:307)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.NoSuchMethodException: org.apache.hadoop.io.ArrayWritable.<init>()
	at java.lang.Class.getConstructor0(Class.java:2849)
	at java.lang.Class.getDeclaredConstructor(Class.java:2053)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:125)
	... 14 more
2016-02-16 19:56:12,742 INFO org.apache.hadoop.mapreduce.Job: Job job_local868320427_0001 running in uber mode : false
2016-02-16 19:56:12,745 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 19:56:12,747 INFO org.apache.hadoop.mapreduce.Job: Job job_local868320427_0001 failed with state FAILED due to: NA
2016-02-16 19:56:12,778 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262583
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=386
		Map output materialized bytes=434
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=434
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=37
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 20:12:56,785 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:12:58,113 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:12:58,127 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:12:59,353 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 20:12:59,368 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 20:12:59,420 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 20:12:59,512 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 20:12:59,833 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1897814910_0001
2016-02-16 20:13:00,616 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 20:13:00,618 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1897814910_0001
2016-02-16 20:13:00,621 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 20:13:00,646 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:13:00,658 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 20:13:00,881 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 20:13:00,882 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1897814910_0001_m_000000_0
2016-02-16 20:13:00,975 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:13:01,010 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:13:01,016 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 20:13:01,128 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 20:13:01,128 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 20:13:01,128 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 20:13:01,129 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 20:13:01,129 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 20:13:01,133 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 20:13:01,148 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 20:13:01,148 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 20:13:01,148 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 20:13:01,155 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 323; bufvoid = 104857600
2016-02-16 20:13:01,155 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 20:13:01,170 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 20:13:01,173 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1897814910_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 20:13:01,192 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 20:13:01,193 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1897814910_0001_m_000000_0' done.
2016-02-16 20:13:01,193 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1897814910_0001_m_000000_0
2016-02-16 20:13:01,194 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 20:13:01,199 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 20:13:01,199 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1897814910_0001_r_000000_0
2016-02-16 20:13:01,208 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:13:01,208 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:13:01,212 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42f599c6
2016-02-16 20:13:01,229 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 20:13:01,241 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1897814910_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 20:13:01,294 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1897814910_0001_m_000000_0 decomp: 367 len: 371 to MEMORY
2016-02-16 20:13:01,300 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 367 bytes from map-output for attempt_local1897814910_0001_m_000000_0
2016-02-16 20:13:01,303 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 367, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->367
2016-02-16 20:13:01,305 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 20:13:01,307 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:13:01,308 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 20:13:01,314 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:13:01,315 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:13:01,317 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 367 bytes to disk to satisfy reduce memory limit
2016-02-16 20:13:01,317 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 371 bytes from disk
2016-02-16 20:13:01,318 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 20:13:01,319 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:13:01,319 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:13:01,320 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:13:01,327 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 20:13:01,336 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1897814910_0001_r_000000_0 is done. And is in the process of committing
2016-02-16 20:13:01,338 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:13:01,338 INFO org.apache.hadoop.mapred.Task: Task attempt_local1897814910_0001_r_000000_0 is allowed to commit now
2016-02-16 20:13:01,339 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1897814910_0001_r_000000_0' to file:/home/cloudera/Desktop/hw3_output/_temporary/0/task_local1897814910_0001_r_000000
2016-02-16 20:13:01,340 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-16 20:13:01,340 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1897814910_0001_r_000000_0' done.
2016-02-16 20:13:01,344 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1897814910_0001_r_000000_0
2016-02-16 20:13:01,345 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 20:13:01,622 INFO org.apache.hadoop.mapreduce.Job: Job job_local1897814910_0001 running in uber mode : false
2016-02-16 20:13:01,628 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-16 20:13:01,631 INFO org.apache.hadoop.mapreduce.Job: Job job_local1897814910_0001 completed successfully
2016-02-16 20:13:01,645 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1306
		FILE: Number of bytes written=528199
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=323
		Map output materialized bytes=371
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=371
		Reduce input records=21
		Reduce output records=6
		Spilled Records=42
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=41
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=36
2016-02-16 20:21:01,795 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:21:02,518 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:21:02,528 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:21:03,255 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 20:21:03,258 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 20:21:03,280 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 20:21:03,350 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 20:21:03,721 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1147079450_0001
2016-02-16 20:21:04,400 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 20:21:04,401 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1147079450_0001
2016-02-16 20:21:04,403 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 20:21:04,435 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:21:04,443 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 20:21:04,646 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 20:21:04,647 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1147079450_0001_m_000000_0
2016-02-16 20:21:04,728 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:21:04,794 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:21:04,811 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 20:21:05,215 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 20:21:05,215 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 20:21:05,215 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 20:21:05,216 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 20:21:05,216 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 20:21:05,226 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 20:21:05,256 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 20:21:05,256 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 20:21:05,256 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 20:21:05,260 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 323; bufvoid = 104857600
2016-02-16 20:21:05,262 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 20:21:05,289 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 20:21:05,297 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1147079450_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 20:21:05,329 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 20:21:05,332 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1147079450_0001_m_000000_0' done.
2016-02-16 20:21:05,333 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1147079450_0001_m_000000_0
2016-02-16 20:21:05,334 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 20:21:05,344 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 20:21:05,344 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1147079450_0001_r_000000_0
2016-02-16 20:21:05,378 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:21:05,379 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:21:05,388 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2888dcd1
2016-02-16 20:21:05,411 INFO org.apache.hadoop.mapreduce.Job: Job job_local1147079450_0001 running in uber mode : false
2016-02-16 20:21:05,412 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 20:21:05,438 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 20:21:05,455 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1147079450_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 20:21:05,574 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1147079450_0001_m_000000_0 decomp: 367 len: 371 to MEMORY
2016-02-16 20:21:05,594 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 367 bytes from map-output for attempt_local1147079450_0001_m_000000_0
2016-02-16 20:21:05,600 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 367, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->367
2016-02-16 20:21:05,606 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 20:21:05,607 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:21:05,609 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 20:21:05,624 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:21:05,627 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:21:05,631 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 367 bytes to disk to satisfy reduce memory limit
2016-02-16 20:21:05,632 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 371 bytes from disk
2016-02-16 20:21:05,633 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 20:21:05,633 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:21:05,634 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:21:05,636 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:21:05,651 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 20:21:05,667 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1147079450_0001_r_000000_0 is done. And is in the process of committing
2016-02-16 20:21:05,671 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:21:05,672 INFO org.apache.hadoop.mapred.Task: Task attempt_local1147079450_0001_r_000000_0 is allowed to commit now
2016-02-16 20:21:05,674 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1147079450_0001_r_000000_0' to file:/home/cloudera/Desktop/hw3_output/_temporary/0/task_local1147079450_0001_r_000000
2016-02-16 20:21:05,688 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-16 20:21:05,689 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1147079450_0001_r_000000_0' done.
2016-02-16 20:21:05,689 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1147079450_0001_r_000000_0
2016-02-16 20:21:05,689 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 20:21:06,421 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-16 20:21:06,422 INFO org.apache.hadoop.mapreduce.Job: Job job_local1147079450_0001 completed successfully
2016-02-16 20:21:06,436 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1306
		FILE: Number of bytes written=528199
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=323
		Map output materialized bytes=371
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=371
		Reduce input records=21
		Reduce output records=6
		Spilled Records=42
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=180
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=36
2016-02-16 20:26:17,748 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:26:18,575 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:26:18,580 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:26:18,705 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/Desktop/hw3_output already exists
2016-02-16 20:26:38,142 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:26:38,849 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:26:38,854 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:26:39,631 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 20:26:39,634 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 20:26:39,657 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 20:26:39,719 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 20:26:40,081 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1381228297_0001
2016-02-16 20:26:40,699 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 20:26:40,700 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1381228297_0001
2016-02-16 20:26:40,703 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 20:26:40,725 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:26:40,729 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 20:26:40,924 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 20:26:40,926 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1381228297_0001_m_000000_0
2016-02-16 20:26:41,003 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:26:41,031 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:26:41,035 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 20:26:41,148 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 20:26:41,149 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 20:26:41,149 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 20:26:41,149 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 20:26:41,149 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 20:26:41,153 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 20:26:41,166 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 20:26:41,167 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 20:26:41,167 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 20:26:41,173 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 323; bufvoid = 104857600
2016-02-16 20:26:41,173 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 20:26:41,190 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 20:26:41,193 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1381228297_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 20:26:41,203 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 20:26:41,204 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1381228297_0001_m_000000_0' done.
2016-02-16 20:26:41,204 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1381228297_0001_m_000000_0
2016-02-16 20:26:41,204 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 20:26:41,209 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 20:26:41,210 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1381228297_0001_r_000000_0
2016-02-16 20:26:41,218 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:26:41,218 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:26:41,222 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7de69f2
2016-02-16 20:26:41,244 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 20:26:41,252 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1381228297_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 20:26:41,315 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1381228297_0001_m_000000_0 decomp: 367 len: 371 to MEMORY
2016-02-16 20:26:41,322 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 367 bytes from map-output for attempt_local1381228297_0001_m_000000_0
2016-02-16 20:26:41,323 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 367, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->367
2016-02-16 20:26:41,326 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 20:26:41,328 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:26:41,329 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 20:26:41,335 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:26:41,335 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:26:41,337 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 367 bytes to disk to satisfy reduce memory limit
2016-02-16 20:26:41,338 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 371 bytes from disk
2016-02-16 20:26:41,339 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 20:26:41,339 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:26:41,340 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:26:41,342 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:26:41,349 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 20:26:41,365 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1381228297_0001_r_000000_0 is done. And is in the process of committing
2016-02-16 20:26:41,368 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:26:41,368 INFO org.apache.hadoop.mapred.Task: Task attempt_local1381228297_0001_r_000000_0 is allowed to commit now
2016-02-16 20:26:41,369 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1381228297_0001_r_000000_0' to file:/home/cloudera/Desktop/hw3_output/_temporary/0/task_local1381228297_0001_r_000000
2016-02-16 20:26:41,375 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-16 20:26:41,376 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1381228297_0001_r_000000_0' done.
2016-02-16 20:26:41,376 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1381228297_0001_r_000000_0
2016-02-16 20:26:41,376 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 20:26:41,718 INFO org.apache.hadoop.mapreduce.Job: Job job_local1381228297_0001 running in uber mode : false
2016-02-16 20:26:41,719 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-16 20:26:41,720 INFO org.apache.hadoop.mapreduce.Job: Job job_local1381228297_0001 completed successfully
2016-02-16 20:26:41,732 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1306
		FILE: Number of bytes written=528199
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=323
		Map output materialized bytes=371
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=371
		Reduce input records=21
		Reduce output records=6
		Spilled Records=42
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=44
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=36
2016-02-16 20:27:47,099 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:27:47,824 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:27:47,830 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:27:48,496 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 20:27:48,499 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 20:27:48,516 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 20:27:48,564 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 20:27:48,881 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local599020928_0001
2016-02-16 20:27:49,495 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 20:27:49,496 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local599020928_0001
2016-02-16 20:27:49,507 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 20:27:49,535 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:27:49,546 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 20:27:49,753 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 20:27:49,754 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local599020928_0001_m_000000_0
2016-02-16 20:27:49,828 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:27:49,871 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:27:49,878 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 20:27:50,058 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 20:27:50,059 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 20:27:50,060 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 20:27:50,060 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 20:27:50,060 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 20:27:50,070 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 20:27:50,093 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 20:27:50,099 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 20:27:50,099 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 20:27:50,103 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 323; bufvoid = 104857600
2016-02-16 20:27:50,103 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 20:27:50,140 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 20:27:50,148 INFO org.apache.hadoop.mapred.Task: Task:attempt_local599020928_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 20:27:50,179 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 20:27:50,180 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local599020928_0001_m_000000_0' done.
2016-02-16 20:27:50,183 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local599020928_0001_m_000000_0
2016-02-16 20:27:50,184 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 20:27:50,190 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 20:27:50,190 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local599020928_0001_r_000000_0
2016-02-16 20:27:50,216 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:27:50,217 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:27:50,225 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7de69f2
2016-02-16 20:27:50,256 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 20:27:50,271 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local599020928_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 20:27:50,375 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local599020928_0001_m_000000_0 decomp: 367 len: 371 to MEMORY
2016-02-16 20:27:50,385 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 367 bytes from map-output for attempt_local599020928_0001_m_000000_0
2016-02-16 20:27:50,391 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 367, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->367
2016-02-16 20:27:50,393 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 20:27:50,395 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:27:50,395 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 20:27:50,409 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:27:50,409 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:27:50,412 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 367 bytes to disk to satisfy reduce memory limit
2016-02-16 20:27:50,413 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 371 bytes from disk
2016-02-16 20:27:50,416 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 20:27:50,417 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:27:50,417 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:27:50,419 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:27:50,439 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 20:27:50,461 INFO org.apache.hadoop.mapred.Task: Task:attempt_local599020928_0001_r_000000_0 is done. And is in the process of committing
2016-02-16 20:27:50,464 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:27:50,467 INFO org.apache.hadoop.mapred.Task: Task attempt_local599020928_0001_r_000000_0 is allowed to commit now
2016-02-16 20:27:50,467 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local599020928_0001_r_000000_0' to file:/home/cloudera/Desktop/hw3_output/_temporary/0/task_local599020928_0001_r_000000
2016-02-16 20:27:50,475 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-16 20:27:50,475 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local599020928_0001_r_000000_0' done.
2016-02-16 20:27:50,475 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local599020928_0001_r_000000_0
2016-02-16 20:27:50,476 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 20:27:50,507 INFO org.apache.hadoop.mapreduce.Job: Job job_local599020928_0001 running in uber mode : false
2016-02-16 20:27:50,508 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-16 20:27:50,509 INFO org.apache.hadoop.mapreduce.Job: Job job_local599020928_0001 completed successfully
2016-02-16 20:27:50,571 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1306
		FILE: Number of bytes written=525411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=323
		Map output materialized bytes=371
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=371
		Reduce input records=21
		Reduce output records=6
		Spilled Records=42
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=73
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=36
2016-02-16 20:35:18,254 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:35:19,050 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:35:19,058 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:35:20,041 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 20:35:20,056 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 20:35:20,093 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 20:35:20,191 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 20:35:20,525 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1696674279_0001
2016-02-16 20:35:21,178 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 20:35:21,179 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1696674279_0001
2016-02-16 20:35:21,184 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 20:35:21,205 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:35:21,210 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 20:35:21,407 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 20:35:21,408 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1696674279_0001_m_000000_0
2016-02-16 20:35:21,486 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:35:21,502 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:35:21,506 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 20:35:21,613 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 20:35:21,613 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 20:35:21,613 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 20:35:21,613 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 20:35:21,613 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 20:35:21,617 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 20:35:21,628 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 20:35:21,628 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 20:35:21,628 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 20:35:21,628 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 323; bufvoid = 104857600
2016-02-16 20:35:21,628 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 20:35:21,641 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 20:35:21,645 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1696674279_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 20:35:21,653 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 20:35:21,654 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1696674279_0001_m_000000_0' done.
2016-02-16 20:35:21,654 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1696674279_0001_m_000000_0
2016-02-16 20:35:21,654 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 20:35:21,658 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 20:35:21,658 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1696674279_0001_r_000000_0
2016-02-16 20:35:21,667 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:35:21,667 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:35:21,675 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@413bc53f
2016-02-16 20:35:21,702 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 20:35:21,709 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1696674279_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 20:35:21,754 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1696674279_0001_m_000000_0 decomp: 367 len: 371 to MEMORY
2016-02-16 20:35:21,760 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 367 bytes from map-output for attempt_local1696674279_0001_m_000000_0
2016-02-16 20:35:21,762 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 367, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->367
2016-02-16 20:35:21,763 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 20:35:21,770 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:35:21,770 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 20:35:21,784 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:35:21,784 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:35:21,786 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 367 bytes to disk to satisfy reduce memory limit
2016-02-16 20:35:21,786 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 371 bytes from disk
2016-02-16 20:35:21,787 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 20:35:21,787 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:35:21,788 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:35:21,789 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:35:21,796 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 20:35:21,803 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 20:35:21,806 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1696674279_0001
java.lang.Exception: java.lang.StringIndexOutOfBoundsException: String index out of range: -5
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.StringIndexOutOfBoundsException: String index out of range: -5
	at java.lang.String.substring(String.java:1911)
	at PageRankReducer.reduce(PageRankReducer.java:25)
	at PageRankReducer.reduce(PageRankReducer.java:1)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 20:35:22,189 INFO org.apache.hadoop.mapreduce.Job: Job job_local1696674279_0001 running in uber mode : false
2016-02-16 20:35:22,190 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 20:35:22,191 INFO org.apache.hadoop.mapreduce.Job: Job job_local1696674279_0001 failed with state FAILED due to: NA
2016-02-16 20:35:22,202 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263896
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=323
		Map output materialized bytes=371
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=371
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=34
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 20:35:43,190 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:35:43,893 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:35:43,895 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:35:44,540 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 20:35:44,543 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 20:35:44,562 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 20:35:44,611 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 20:35:44,916 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local961837160_0001
2016-02-16 20:35:45,612 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 20:35:45,615 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local961837160_0001
2016-02-16 20:35:45,619 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 20:35:45,642 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:35:45,648 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 20:35:45,827 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 20:35:45,829 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local961837160_0001_m_000000_0
2016-02-16 20:35:45,879 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:35:45,900 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:35:45,904 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 20:35:46,005 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 20:35:46,009 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 20:35:46,010 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 20:35:46,011 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 20:35:46,011 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 20:35:46,015 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 20:35:46,029 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 20:35:46,029 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 20:35:46,029 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 20:35:46,035 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 323; bufvoid = 104857600
2016-02-16 20:35:46,035 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 20:35:46,046 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 20:35:46,050 INFO org.apache.hadoop.mapred.Task: Task:attempt_local961837160_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 20:35:46,066 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 20:35:46,066 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local961837160_0001_m_000000_0' done.
2016-02-16 20:35:46,066 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local961837160_0001_m_000000_0
2016-02-16 20:35:46,066 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 20:35:46,070 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 20:35:46,070 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local961837160_0001_r_000000_0
2016-02-16 20:35:46,079 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:35:46,079 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:35:46,084 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1ca68033
2016-02-16 20:35:46,098 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 20:35:46,105 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local961837160_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 20:35:46,200 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local961837160_0001_m_000000_0 decomp: 367 len: 371 to MEMORY
2016-02-16 20:35:46,212 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 367 bytes from map-output for attempt_local961837160_0001_m_000000_0
2016-02-16 20:35:46,218 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 367, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->367
2016-02-16 20:35:46,219 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 20:35:46,221 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:35:46,222 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 20:35:46,234 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:35:46,237 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:35:46,237 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 367 bytes to disk to satisfy reduce memory limit
2016-02-16 20:35:46,242 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 371 bytes from disk
2016-02-16 20:35:46,243 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 20:35:46,243 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:35:46,244 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:35:46,244 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:35:46,259 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 20:35:46,278 INFO org.apache.hadoop.mapred.Task: Task:attempt_local961837160_0001_r_000000_0 is done. And is in the process of committing
2016-02-16 20:35:46,283 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:35:46,285 INFO org.apache.hadoop.mapred.Task: Task attempt_local961837160_0001_r_000000_0 is allowed to commit now
2016-02-16 20:35:46,286 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local961837160_0001_r_000000_0' to file:/home/cloudera/Desktop/hw3_output/_temporary/0/task_local961837160_0001_r_000000
2016-02-16 20:35:46,293 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-16 20:35:46,297 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local961837160_0001_r_000000_0' done.
2016-02-16 20:35:46,297 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local961837160_0001_r_000000_0
2016-02-16 20:35:46,297 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 20:35:46,624 INFO org.apache.hadoop.mapreduce.Job: Job job_local961837160_0001 running in uber mode : false
2016-02-16 20:35:46,627 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-16 20:35:46,628 INFO org.apache.hadoop.mapreduce.Job: Job job_local961837160_0001 completed successfully
2016-02-16 20:35:46,656 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1306
		FILE: Number of bytes written=525411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=323
		Map output materialized bytes=371
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=371
		Reduce input records=21
		Reduce output records=6
		Spilled Records=42
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=43
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=36
2016-02-16 20:36:58,485 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:36:59,289 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:36:59,298 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:37:00,318 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 20:37:00,332 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 20:37:00,379 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 20:37:00,502 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 20:37:00,852 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local215268290_0001
2016-02-16 20:37:01,539 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 20:37:01,540 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local215268290_0001
2016-02-16 20:37:01,542 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 20:37:01,565 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:37:01,570 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 20:37:01,759 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 20:37:01,761 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local215268290_0001_m_000000_0
2016-02-16 20:37:01,837 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:37:01,861 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:37:01,871 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 20:37:01,974 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 20:37:01,976 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 20:37:01,976 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 20:37:01,976 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 20:37:01,976 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 20:37:01,981 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 20:37:01,995 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 20:37:01,995 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 20:37:01,995 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 20:37:02,001 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 323; bufvoid = 104857600
2016-02-16 20:37:02,002 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 20:37:02,013 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 20:37:02,017 INFO org.apache.hadoop.mapred.Task: Task:attempt_local215268290_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 20:37:02,029 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 20:37:02,029 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local215268290_0001_m_000000_0' done.
2016-02-16 20:37:02,029 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local215268290_0001_m_000000_0
2016-02-16 20:37:02,030 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 20:37:02,034 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 20:37:02,034 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local215268290_0001_r_000000_0
2016-02-16 20:37:02,041 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:37:02,042 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:37:02,045 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6f9d96dd
2016-02-16 20:37:02,058 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 20:37:02,065 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local215268290_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 20:37:02,121 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local215268290_0001_m_000000_0 decomp: 367 len: 371 to MEMORY
2016-02-16 20:37:02,125 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 367 bytes from map-output for attempt_local215268290_0001_m_000000_0
2016-02-16 20:37:02,127 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 367, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->367
2016-02-16 20:37:02,129 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 20:37:02,132 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:37:02,132 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 20:37:02,139 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:37:02,140 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:37:02,141 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 367 bytes to disk to satisfy reduce memory limit
2016-02-16 20:37:02,142 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 371 bytes from disk
2016-02-16 20:37:02,142 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 20:37:02,142 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:37:02,143 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:37:02,143 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:37:02,150 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 20:37:02,162 INFO org.apache.hadoop.mapred.Task: Task:attempt_local215268290_0001_r_000000_0 is done. And is in the process of committing
2016-02-16 20:37:02,165 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:37:02,165 INFO org.apache.hadoop.mapred.Task: Task attempt_local215268290_0001_r_000000_0 is allowed to commit now
2016-02-16 20:37:02,166 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local215268290_0001_r_000000_0' to file:/home/cloudera/Desktop/hw3_output/_temporary/0/task_local215268290_0001_r_000000
2016-02-16 20:37:02,171 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-16 20:37:02,172 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local215268290_0001_r_000000_0' done.
2016-02-16 20:37:02,173 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local215268290_0001_r_000000_0
2016-02-16 20:37:02,173 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 20:37:02,551 INFO org.apache.hadoop.mapreduce.Job: Job job_local215268290_0001 running in uber mode : false
2016-02-16 20:37:02,553 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-16 20:37:02,554 INFO org.apache.hadoop.mapreduce.Job: Job job_local215268290_0001 completed successfully
2016-02-16 20:37:02,566 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1306
		FILE: Number of bytes written=525411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=323
		Map output materialized bytes=371
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=371
		Reduce input records=21
		Reduce output records=6
		Spilled Records=42
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=37
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=36
2016-02-16 20:39:21,998 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:39:22,971 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:39:22,976 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:39:23,964 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 20:39:23,968 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 20:39:24,000 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 20:39:24,089 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 20:39:24,506 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1475074117_0001
2016-02-16 20:39:25,708 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 20:39:25,710 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1475074117_0001
2016-02-16 20:39:25,713 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 20:39:25,744 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:39:25,754 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 20:39:25,948 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 20:39:25,951 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1475074117_0001_m_000000_0
2016-02-16 20:39:26,026 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:39:26,065 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:39:26,072 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 20:39:26,294 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 20:39:26,294 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 20:39:26,294 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 20:39:26,295 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 20:39:26,295 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 20:39:26,309 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 20:39:26,342 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 20:39:26,343 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 20:39:26,343 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 20:39:26,350 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 323; bufvoid = 104857600
2016-02-16 20:39:26,350 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 20:39:26,385 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 20:39:26,400 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1475074117_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 20:39:26,451 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 20:39:26,453 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1475074117_0001_m_000000_0' done.
2016-02-16 20:39:26,453 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1475074117_0001_m_000000_0
2016-02-16 20:39:26,453 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 20:39:26,463 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 20:39:26,464 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1475074117_0001_r_000000_0
2016-02-16 20:39:26,494 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:39:26,501 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:39:26,508 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5ee0c078
2016-02-16 20:39:26,585 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 20:39:26,604 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1475074117_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 20:39:26,717 INFO org.apache.hadoop.mapreduce.Job: Job job_local1475074117_0001 running in uber mode : false
2016-02-16 20:39:26,718 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 20:39:26,729 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1475074117_0001_m_000000_0 decomp: 367 len: 371 to MEMORY
2016-02-16 20:39:26,741 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 367 bytes from map-output for attempt_local1475074117_0001_m_000000_0
2016-02-16 20:39:26,747 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 367, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->367
2016-02-16 20:39:26,749 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 20:39:26,751 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:39:26,753 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 20:39:26,768 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:39:26,771 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:39:26,775 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 367 bytes to disk to satisfy reduce memory limit
2016-02-16 20:39:26,776 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 371 bytes from disk
2016-02-16 20:39:26,778 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 20:39:26,783 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:39:26,783 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:39:26,784 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:39:26,799 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 20:39:26,823 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 20:39:26,832 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local1475074117_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "F"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.NumberFormatException: For input string: "F"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1250)
	at java.lang.Float.parseFloat(Float.java:452)
	at PageRankReducer.reduce(PageRankReducer.java:33)
	at PageRankReducer.reduce(PageRankReducer.java:1)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 20:39:27,730 INFO org.apache.hadoop.mapreduce.Job: Job job_local1475074117_0001 failed with state FAILED due to: NA
2016-02-16 20:39:27,746 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=263896
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=323
		Map output materialized bytes=371
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=371
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=93
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 20:41:06,863 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:41:07,609 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:41:07,613 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:41:07,707 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/Desktop/hw3_output already exists
2016-02-16 20:41:14,824 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:41:15,518 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:41:15,528 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:41:16,233 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 20:41:16,238 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 20:41:16,263 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 20:41:16,328 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 20:41:16,638 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local429713202_0001
2016-02-16 20:41:17,253 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 20:41:17,255 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local429713202_0001
2016-02-16 20:41:17,257 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 20:41:17,279 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:41:17,282 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 20:41:17,474 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 20:41:17,475 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local429713202_0001_m_000000_0
2016-02-16 20:41:17,556 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:41:17,602 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:41:17,606 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 20:41:17,780 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 20:41:17,783 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 20:41:17,783 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 20:41:17,783 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 20:41:17,784 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 20:41:17,792 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 20:41:17,822 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 20:41:17,823 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 20:41:17,823 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 20:41:17,828 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 323; bufvoid = 104857600
2016-02-16 20:41:17,829 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 20:41:17,859 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 20:41:17,866 INFO org.apache.hadoop.mapred.Task: Task:attempt_local429713202_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 20:41:17,895 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 20:41:17,896 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local429713202_0001_m_000000_0' done.
2016-02-16 20:41:17,896 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local429713202_0001_m_000000_0
2016-02-16 20:41:17,896 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 20:41:17,906 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 20:41:17,906 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local429713202_0001_r_000000_0
2016-02-16 20:41:17,926 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:41:17,927 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:41:17,944 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2888dcd1
2016-02-16 20:41:17,987 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 20:41:18,008 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local429713202_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 20:41:18,109 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local429713202_0001_m_000000_0 decomp: 367 len: 371 to MEMORY
2016-02-16 20:41:18,123 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 367 bytes from map-output for attempt_local429713202_0001_m_000000_0
2016-02-16 20:41:18,125 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 367, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->367
2016-02-16 20:41:18,128 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 20:41:18,129 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:41:18,130 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 20:41:18,142 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:41:18,145 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:41:18,149 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 367 bytes to disk to satisfy reduce memory limit
2016-02-16 20:41:18,150 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 371 bytes from disk
2016-02-16 20:41:18,150 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 20:41:18,151 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:41:18,152 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:41:18,154 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:41:18,173 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 20:41:18,198 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 20:41:18,201 WARN org.apache.hadoop.mapred.LocalJobRunner: job_local429713202_0001
java.lang.Exception: java.lang.NumberFormatException: For input string: "F"
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.NumberFormatException: For input string: "F"
	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1250)
	at java.lang.Float.parseFloat(Float.java:452)
	at PageRankReducer.reduce(PageRankReducer.java:33)
	at PageRankReducer.reduce(PageRankReducer.java:1)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-02-16 20:41:18,264 INFO org.apache.hadoop.mapreduce.Job: Job job_local429713202_0001 running in uber mode : false
2016-02-16 20:41:18,266 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-16 20:41:18,268 INFO org.apache.hadoop.mapreduce.Job: Job job_local429713202_0001 failed with state FAILED due to: NA
2016-02-16 20:41:18,313 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=266
		FILE: Number of bytes written=262502
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=323
		Map output materialized bytes=371
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=371
		Reduce input records=0
		Reduce output records=0
		Spilled Records=21
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=48
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=165613568
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=0
2016-02-16 20:42:45,860 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-16 20:42:46,754 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-16 20:42:46,762 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-16 20:42:47,459 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-16 20:42:47,461 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-16 20:42:47,482 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-16 20:42:47,536 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-16 20:42:47,850 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1921171820_0001
2016-02-16 20:42:48,519 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-16 20:42:48,520 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1921171820_0001
2016-02-16 20:42:48,528 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-16 20:42:48,551 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:42:48,560 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-16 20:42:48,750 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-16 20:42:48,751 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1921171820_0001_m_000000_0
2016-02-16 20:42:48,840 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:42:48,885 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:42:48,891 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/pagerank/hw3_inputfile:0+95
2016-02-16 20:42:49,076 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-16 20:42:49,079 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-16 20:42:49,079 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-16 20:42:49,079 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-16 20:42:49,079 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-16 20:42:49,093 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-16 20:42:49,118 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-16 20:42:49,120 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-16 20:42:49,120 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-16 20:42:49,127 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 323; bufvoid = 104857600
2016-02-16 20:42:49,135 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214316(104857264); length = 81/6553600
2016-02-16 20:42:49,163 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-16 20:42:49,171 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1921171820_0001_m_000000_0 is done. And is in the process of committing
2016-02-16 20:42:49,192 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-16 20:42:49,195 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1921171820_0001_m_000000_0' done.
2016-02-16 20:42:49,195 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1921171820_0001_m_000000_0
2016-02-16 20:42:49,195 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-16 20:42:49,201 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-16 20:42:49,201 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1921171820_0001_r_000000_0
2016-02-16 20:42:49,222 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-16 20:42:49,223 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-16 20:42:49,234 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4b4c7b84
2016-02-16 20:42:49,279 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-16 20:42:49,291 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1921171820_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-16 20:42:49,399 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1921171820_0001_m_000000_0 decomp: 367 len: 371 to MEMORY
2016-02-16 20:42:49,413 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 367 bytes from map-output for attempt_local1921171820_0001_m_000000_0
2016-02-16 20:42:49,415 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 367, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->367
2016-02-16 20:42:49,423 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-16 20:42:49,424 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:42:49,426 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-16 20:42:49,439 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:42:49,440 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:42:49,443 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 367 bytes to disk to satisfy reduce memory limit
2016-02-16 20:42:49,444 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 371 bytes from disk
2016-02-16 20:42:49,446 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-16 20:42:49,447 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-16 20:42:49,450 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 363 bytes
2016-02-16 20:42:49,450 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:42:49,466 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-16 20:42:49,489 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1921171820_0001_r_000000_0 is done. And is in the process of committing
2016-02-16 20:42:49,491 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-16 20:42:49,495 INFO org.apache.hadoop.mapred.Task: Task attempt_local1921171820_0001_r_000000_0 is allowed to commit now
2016-02-16 20:42:49,497 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1921171820_0001_r_000000_0' to file:/home/cloudera/Desktop/hw3_output/_temporary/0/task_local1921171820_0001_r_000000
2016-02-16 20:42:49,506 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-16 20:42:49,506 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1921171820_0001_r_000000_0' done.
2016-02-16 20:42:49,509 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1921171820_0001_r_000000_0
2016-02-16 20:42:49,509 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-16 20:42:49,530 INFO org.apache.hadoop.mapreduce.Job: Job job_local1921171820_0001 running in uber mode : false
2016-02-16 20:42:49,531 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-16 20:42:50,534 INFO org.apache.hadoop.mapreduce.Job: Job job_local1921171820_0001 completed successfully
2016-02-16 20:42:50,548 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1306
		FILE: Number of bytes written=528251
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=21
		Map output bytes=323
		Map output materialized bytes=371
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=371
		Reduce input records=21
		Reduce output records=6
		Spilled Records=42
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=78
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=95
	File Output Format Counters 
		Bytes Written=88
