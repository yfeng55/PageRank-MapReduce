2016-02-09 14:07:07,702 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:18:27,799 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:19:03,996 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:32:32,726 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:32:33,409 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 14:32:33,414 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 14:32:34,068 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-09 14:32:34,072 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-09 14:32:34,091 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-09 14:32:34,136 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-09 14:32:34,433 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1420488232_0001
2016-02-09 14:32:35,054 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-09 14:32:35,056 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1420488232_0001
2016-02-09 14:32:35,058 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-09 14:32:35,083 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:32:35,093 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-09 14:32:35,284 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-09 14:32:35,285 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1420488232_0001_m_000000_0
2016-02-09 14:32:35,358 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:32:35,396 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 14:32:35,403 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/wordcount/hw2_inputfile:0+289
2016-02-09 14:32:35,617 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-09 14:32:35,619 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-09 14:32:35,620 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-09 14:32:35,623 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-09 14:32:35,623 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-09 14:32:35,634 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-09 14:32:35,647 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-09 14:32:35,651 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-09 14:32:35,652 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-09 14:32:35,652 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 22; bufvoid = 104857600
2016-02-09 14:32:35,652 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
2016-02-09 14:32:35,673 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-09 14:32:35,680 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1420488232_0001_m_000000_0 is done. And is in the process of committing
2016-02-09 14:32:35,700 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-09 14:32:35,704 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1420488232_0001_m_000000_0' done.
2016-02-09 14:32:35,704 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1420488232_0001_m_000000_0
2016-02-09 14:32:35,704 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-09 14:32:35,708 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-09 14:32:35,711 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1420488232_0001_r_000000_0
2016-02-09 14:32:35,738 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:32:35,740 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 14:32:35,752 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@76fc3726
2016-02-09 14:32:35,789 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-09 14:32:35,803 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1420488232_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-09 14:32:35,902 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1420488232_0001_m_000000_0 decomp: 28 len: 32 to MEMORY
2016-02-09 14:32:35,914 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 28 bytes from map-output for attempt_local1420488232_0001_m_000000_0
2016-02-09 14:32:35,918 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 28, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->28
2016-02-09 14:32:35,923 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-09 14:32:35,925 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:32:35,926 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-09 14:32:35,935 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 14:32:35,937 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 22 bytes
2016-02-09 14:32:35,939 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 28 bytes to disk to satisfy reduce memory limit
2016-02-09 14:32:35,943 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 32 bytes from disk
2016-02-09 14:32:35,944 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-09 14:32:35,944 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 14:32:35,945 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 22 bytes
2016-02-09 14:32:35,946 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:32:35,966 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-09 14:32:35,977 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1420488232_0001_r_000000_0 is done. And is in the process of committing
2016-02-09 14:32:35,983 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:32:35,984 INFO org.apache.hadoop.mapred.Task: Task attempt_local1420488232_0001_r_000000_0 is allowed to commit now
2016-02-09 14:32:35,987 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1420488232_0001_r_000000_0' to file:/home/cloudera/Desktop/hw2_output/_temporary/0/task_local1420488232_0001_r_000000
2016-02-09 14:32:35,992 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-09 14:32:35,996 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1420488232_0001_r_000000_0' done.
2016-02-09 14:32:35,997 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1420488232_0001_r_000000_0
2016-02-09 14:32:35,998 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-09 14:32:36,067 INFO org.apache.hadoop.mapreduce.Job: Job job_local1420488232_0001 running in uber mode : false
2016-02-09 14:32:36,068 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-09 14:32:36,069 INFO org.apache.hadoop.mapreduce.Job: Job job_local1420488232_0001 completed successfully
2016-02-09 14:32:36,115 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1022
		FILE: Number of bytes written=527214
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=2
		Map output bytes=22
		Map output materialized bytes=32
		Input split bytes=118
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=32
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=68
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=30
2016-02-09 14:36:07,597 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:36:08,551 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 14:36:08,555 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 14:36:08,666 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/Desktop/hw2_output already exists
2016-02-09 14:36:29,221 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:36:29,936 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 14:36:29,942 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 14:36:30,050 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/Desktop/hw2_output already exists
2016-02-09 14:36:54,247 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:36:54,997 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 14:36:54,999 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 14:36:55,993 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-09 14:36:56,009 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-09 14:36:56,064 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-09 14:36:56,183 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-09 14:36:56,543 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1217746420_0001
2016-02-09 14:36:57,177 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-09 14:36:57,178 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1217746420_0001
2016-02-09 14:36:57,188 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-09 14:36:57,202 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:36:57,208 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-09 14:36:57,407 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-09 14:36:57,410 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1217746420_0001_m_000000_0
2016-02-09 14:36:57,491 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:36:57,523 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 14:36:57,527 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/wordcount/hw2_inputfile:0+289
2016-02-09 14:36:57,630 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-09 14:36:57,631 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-09 14:36:57,631 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-09 14:36:57,631 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-09 14:36:57,632 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-09 14:36:57,636 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-09 14:36:57,645 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-09 14:36:57,645 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-09 14:36:57,645 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-09 14:36:57,645 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 42; bufvoid = 104857600
2016-02-09 14:36:57,645 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
2016-02-09 14:36:57,653 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-09 14:36:57,658 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1217746420_0001_m_000000_0 is done. And is in the process of committing
2016-02-09 14:36:57,670 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-09 14:36:57,670 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1217746420_0001_m_000000_0' done.
2016-02-09 14:36:57,670 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1217746420_0001_m_000000_0
2016-02-09 14:36:57,671 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-09 14:36:57,675 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-09 14:36:57,675 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1217746420_0001_r_000000_0
2016-02-09 14:36:57,683 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:36:57,684 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 14:36:57,687 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4583f5e1
2016-02-09 14:36:57,702 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-09 14:36:57,709 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1217746420_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-09 14:36:57,781 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1217746420_0001_m_000000_0 decomp: 52 len: 56 to MEMORY
2016-02-09 14:36:57,786 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 52 bytes from map-output for attempt_local1217746420_0001_m_000000_0
2016-02-09 14:36:57,800 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 52, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->52
2016-02-09 14:36:57,805 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-09 14:36:57,807 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:36:57,808 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-09 14:36:57,823 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 14:36:57,823 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 42 bytes
2016-02-09 14:36:57,826 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 52 bytes to disk to satisfy reduce memory limit
2016-02-09 14:36:57,828 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 56 bytes from disk
2016-02-09 14:36:57,829 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-09 14:36:57,829 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 14:36:57,829 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 42 bytes
2016-02-09 14:36:57,831 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:36:57,852 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-09 14:36:57,862 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1217746420_0001_r_000000_0 is done. And is in the process of committing
2016-02-09 14:36:57,867 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:36:57,870 INFO org.apache.hadoop.mapred.Task: Task attempt_local1217746420_0001_r_000000_0 is allowed to commit now
2016-02-09 14:36:57,872 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1217746420_0001_r_000000_0' to file:/home/cloudera/Desktop/hw2_output/_temporary/0/task_local1217746420_0001_r_000000
2016-02-09 14:36:57,881 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-09 14:36:57,881 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1217746420_0001_r_000000_0' done.
2016-02-09 14:36:57,881 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1217746420_0001_r_000000_0
2016-02-09 14:36:57,881 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-09 14:36:58,187 INFO org.apache.hadoop.mapreduce.Job: Job job_local1217746420_0001 running in uber mode : false
2016-02-09 14:36:58,189 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-09 14:36:58,191 INFO org.apache.hadoop.mapreduce.Job: Job job_local1217746420_0001 completed successfully
2016-02-09 14:36:58,205 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1070
		FILE: Number of bytes written=527296
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=4
		Map output bytes=42
		Map output materialized bytes=56
		Input split bytes=118
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=56
		Reduce input records=4
		Reduce output records=3
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=34
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=40
2016-02-09 14:39:14,616 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:39:15,304 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 14:39:15,307 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 14:39:15,383 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/Desktop/hw2_output already exists
2016-02-09 14:39:32,269 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:39:33,063 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 14:39:33,068 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 14:39:34,103 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-09 14:39:34,120 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-09 14:39:34,164 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-09 14:39:34,236 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-09 14:39:34,565 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1956385628_0001
2016-02-09 14:39:35,242 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-09 14:39:35,243 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1956385628_0001
2016-02-09 14:39:35,251 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-09 14:39:35,273 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:39:35,282 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-09 14:39:35,479 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-09 14:39:35,480 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1956385628_0001_m_000000_0
2016-02-09 14:39:35,548 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:39:35,567 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 14:39:35,572 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/wordcount/hw2_inputfile:0+289
2016-02-09 14:39:35,685 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-09 14:39:35,685 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-09 14:39:35,685 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-09 14:39:35,686 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-09 14:39:35,686 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-09 14:39:35,691 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-09 14:39:35,699 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-09 14:39:35,699 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-09 14:39:35,699 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-09 14:39:35,699 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 56; bufvoid = 104857600
2016-02-09 14:39:35,700 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600
2016-02-09 14:39:35,710 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-09 14:39:35,713 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1956385628_0001_m_000000_0 is done. And is in the process of committing
2016-02-09 14:39:35,724 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-09 14:39:35,724 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1956385628_0001_m_000000_0' done.
2016-02-09 14:39:35,724 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1956385628_0001_m_000000_0
2016-02-09 14:39:35,724 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-09 14:39:35,729 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-09 14:39:35,729 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1956385628_0001_r_000000_0
2016-02-09 14:39:35,740 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:39:35,741 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 14:39:35,747 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5408eaf4
2016-02-09 14:39:35,764 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-09 14:39:35,770 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1956385628_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-09 14:39:35,826 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1956385628_0001_m_000000_0 decomp: 68 len: 72 to MEMORY
2016-02-09 14:39:35,837 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 68 bytes from map-output for attempt_local1956385628_0001_m_000000_0
2016-02-09 14:39:35,838 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 68, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->68
2016-02-09 14:39:35,840 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-09 14:39:35,842 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:39:35,844 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-09 14:39:35,852 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 14:39:35,854 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 58 bytes
2016-02-09 14:39:35,855 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 68 bytes to disk to satisfy reduce memory limit
2016-02-09 14:39:35,856 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 72 bytes from disk
2016-02-09 14:39:35,857 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-09 14:39:35,858 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 14:39:35,858 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 58 bytes
2016-02-09 14:39:35,859 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:39:35,866 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-09 14:39:35,873 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1956385628_0001_r_000000_0 is done. And is in the process of committing
2016-02-09 14:39:35,876 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:39:35,876 INFO org.apache.hadoop.mapred.Task: Task attempt_local1956385628_0001_r_000000_0 is allowed to commit now
2016-02-09 14:39:35,877 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1956385628_0001_r_000000_0' to file:/home/cloudera/Desktop/hw2_output/_temporary/0/task_local1956385628_0001_r_000000
2016-02-09 14:39:35,887 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-09 14:39:35,887 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1956385628_0001_r_000000_0' done.
2016-02-09 14:39:35,888 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1956385628_0001_r_000000_0
2016-02-09 14:39:35,890 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-09 14:39:36,246 INFO org.apache.hadoop.mapreduce.Job: Job job_local1956385628_0001 running in uber mode : false
2016-02-09 14:39:36,248 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-09 14:39:36,248 INFO org.apache.hadoop.mapreduce.Job: Job job_local1956385628_0001 completed successfully
2016-02-09 14:39:36,260 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1102
		FILE: Number of bytes written=527344
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=5
		Map output bytes=56
		Map output materialized bytes=72
		Input split bytes=118
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=72
		Reduce input records=5
		Reduce output records=3
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=39
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=40
2016-02-09 14:41:31,340 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:41:32,027 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 14:41:32,035 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 14:41:32,115 WARN org.apache.hadoop.security.UserGroupInformation: PriviledgedActionException as:cloudera (auth:SIMPLE) cause:org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/cloudera/Desktop/hw2_output already exists
2016-02-09 14:41:47,529 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 14:41:48,229 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 14:41:48,235 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 14:41:48,947 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-09 14:41:48,951 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-09 14:41:48,974 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-09 14:41:49,026 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-09 14:41:49,401 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local1511801979_0001
2016-02-09 14:41:50,124 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-09 14:41:50,126 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local1511801979_0001
2016-02-09 14:41:50,129 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-09 14:41:50,159 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:41:50,161 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-09 14:41:50,384 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-09 14:41:50,385 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1511801979_0001_m_000000_0
2016-02-09 14:41:50,463 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:41:50,505 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 14:41:50,513 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/wordcount/hw2_inputfile:0+289
2016-02-09 14:41:50,669 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-09 14:41:50,669 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-09 14:41:50,670 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-09 14:41:50,671 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-09 14:41:50,671 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-09 14:41:50,681 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-09 14:41:50,698 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-09 14:41:50,700 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-09 14:41:50,700 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-09 14:41:50,701 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 135; bufvoid = 104857600
2016-02-09 14:41:50,701 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
2016-02-09 14:41:50,729 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-09 14:41:50,733 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1511801979_0001_m_000000_0 is done. And is in the process of committing
2016-02-09 14:41:50,755 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-09 14:41:50,759 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1511801979_0001_m_000000_0' done.
2016-02-09 14:41:50,759 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1511801979_0001_m_000000_0
2016-02-09 14:41:50,759 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-09 14:41:50,764 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-09 14:41:50,765 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local1511801979_0001_r_000000_0
2016-02-09 14:41:50,792 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 14:41:50,797 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 14:41:50,802 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2dfb4479
2016-02-09 14:41:50,839 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-09 14:41:50,858 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local1511801979_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-09 14:41:50,964 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1511801979_0001_m_000000_0 decomp: 161 len: 165 to MEMORY
2016-02-09 14:41:50,974 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 161 bytes from map-output for attempt_local1511801979_0001_m_000000_0
2016-02-09 14:41:50,980 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 161, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->161
2016-02-09 14:41:50,984 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-09 14:41:50,986 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:41:50,987 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-09 14:41:50,997 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 14:41:50,998 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-09 14:41:51,001 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 161 bytes to disk to satisfy reduce memory limit
2016-02-09 14:41:51,001 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2016-02-09 14:41:51,003 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-09 14:41:51,006 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 14:41:51,007 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-09 14:41:51,007 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:41:51,022 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-09 14:41:51,037 INFO org.apache.hadoop.mapred.Task: Task:attempt_local1511801979_0001_r_000000_0 is done. And is in the process of committing
2016-02-09 14:41:51,039 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 14:41:51,042 INFO org.apache.hadoop.mapred.Task: Task attempt_local1511801979_0001_r_000000_0 is allowed to commit now
2016-02-09 14:41:51,044 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local1511801979_0001_r_000000_0' to file:/home/cloudera/Desktop/hw2_output/_temporary/0/task_local1511801979_0001_r_000000
2016-02-09 14:41:51,057 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-09 14:41:51,057 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local1511801979_0001_r_000000_0' done.
2016-02-09 14:41:51,058 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local1511801979_0001_r_000000_0
2016-02-09 14:41:51,058 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-09 14:41:51,136 INFO org.apache.hadoop.mapreduce.Job: Job job_local1511801979_0001 running in uber mode : false
2016-02-09 14:41:51,139 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-09 14:41:51,140 INFO org.apache.hadoop.mapreduce.Job: Job job_local1511801979_0001 completed successfully
2016-02-09 14:41:51,181 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1288
		FILE: Number of bytes written=527630
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=12
		Map output bytes=135
		Map output materialized bytes=165
		Input split bytes=118
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=165
		Reduce input records=12
		Reduce output records=4
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=50
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=47
2016-02-09 15:25:45,695 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 15:25:46,376 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 15:25:46,384 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 15:25:47,079 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-09 15:25:47,083 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-09 15:25:47,100 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-09 15:25:47,148 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-09 15:25:47,460 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local791498631_0001
2016-02-09 15:25:48,058 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-09 15:25:48,060 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local791498631_0001
2016-02-09 15:25:48,066 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-09 15:25:48,092 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 15:25:48,098 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-09 15:25:48,284 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-09 15:25:48,285 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local791498631_0001_m_000000_0
2016-02-09 15:25:48,363 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 15:25:48,409 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 15:25:48,418 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/wordcount/hw2_inputfile:0+289
2016-02-09 15:25:48,592 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-09 15:25:48,594 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-09 15:25:48,594 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-09 15:25:48,594 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-09 15:25:48,594 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-09 15:25:48,609 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-09 15:25:48,632 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-09 15:25:48,635 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-09 15:25:48,635 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-09 15:25:48,635 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 135; bufvoid = 104857600
2016-02-09 15:25:48,635 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
2016-02-09 15:25:48,669 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-09 15:25:48,688 INFO org.apache.hadoop.mapred.Task: Task:attempt_local791498631_0001_m_000000_0 is done. And is in the process of committing
2016-02-09 15:25:48,722 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-09 15:25:48,728 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local791498631_0001_m_000000_0' done.
2016-02-09 15:25:48,728 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local791498631_0001_m_000000_0
2016-02-09 15:25:48,728 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-09 15:25:48,737 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-09 15:25:48,737 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local791498631_0001_r_000000_0
2016-02-09 15:25:48,767 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 15:25:48,768 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 15:25:48,780 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@10310199
2016-02-09 15:25:48,828 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-09 15:25:48,844 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local791498631_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-09 15:25:48,943 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local791498631_0001_m_000000_0 decomp: 161 len: 165 to MEMORY
2016-02-09 15:25:48,956 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 161 bytes from map-output for attempt_local791498631_0001_m_000000_0
2016-02-09 15:25:48,962 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 161, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->161
2016-02-09 15:25:48,963 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-09 15:25:48,965 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 15:25:48,965 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-09 15:25:48,978 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 15:25:48,980 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-09 15:25:48,983 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 161 bytes to disk to satisfy reduce memory limit
2016-02-09 15:25:48,984 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2016-02-09 15:25:48,986 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-09 15:25:48,989 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 15:25:48,990 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-09 15:25:48,990 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 15:25:49,013 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-09 15:25:49,021 INFO org.apache.hadoop.mapred.Task: Task:attempt_local791498631_0001_r_000000_0 is done. And is in the process of committing
2016-02-09 15:25:49,026 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 15:25:49,027 INFO org.apache.hadoop.mapred.Task: Task attempt_local791498631_0001_r_000000_0 is allowed to commit now
2016-02-09 15:25:49,029 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local791498631_0001_r_000000_0' to file:/home/cloudera/Desktop/hw2_output/_temporary/0/task_local791498631_0001_r_000000
2016-02-09 15:25:49,036 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-09 15:25:49,036 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local791498631_0001_r_000000_0' done.
2016-02-09 15:25:49,038 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local791498631_0001_r_000000_0
2016-02-09 15:25:49,038 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-09 15:25:49,063 INFO org.apache.hadoop.mapreduce.Job: Job job_local791498631_0001 running in uber mode : false
2016-02-09 15:25:49,064 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-09 15:25:50,067 INFO org.apache.hadoop.mapreduce.Job: Job job_local791498631_0001 completed successfully
2016-02-09 15:25:50,078 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1288
		FILE: Number of bytes written=524842
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=12
		Map output bytes=135
		Map output materialized bytes=165
		Input split bytes=118
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=165
		Reduce input records=12
		Reduce output records=4
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=67
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=47
2016-02-09 15:32:06,513 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 15:32:07,482 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 15:32:07,493 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 15:32:08,535 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-09 15:32:08,550 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-09 15:32:08,591 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-09 15:32:08,664 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-09 15:32:09,078 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local681351725_0001
2016-02-09 15:32:09,805 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-09 15:32:09,807 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local681351725_0001
2016-02-09 15:32:09,810 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-09 15:32:09,832 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 15:32:09,841 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-09 15:32:10,035 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-09 15:32:10,036 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local681351725_0001_m_000000_0
2016-02-09 15:32:10,119 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 15:32:10,159 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 15:32:10,164 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/wordcount/hw2_inputfile:0+289
2016-02-09 15:32:10,283 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-09 15:32:10,284 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-09 15:32:10,284 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-09 15:32:10,284 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-09 15:32:10,284 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-09 15:32:10,290 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-09 15:32:10,300 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-09 15:32:10,301 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-09 15:32:10,301 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-09 15:32:10,301 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 135; bufvoid = 104857600
2016-02-09 15:32:10,301 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
2016-02-09 15:32:10,311 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-09 15:32:10,315 INFO org.apache.hadoop.mapred.Task: Task:attempt_local681351725_0001_m_000000_0 is done. And is in the process of committing
2016-02-09 15:32:10,325 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-09 15:32:10,326 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local681351725_0001_m_000000_0' done.
2016-02-09 15:32:10,326 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local681351725_0001_m_000000_0
2016-02-09 15:32:10,326 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-09 15:32:10,330 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-09 15:32:10,330 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local681351725_0001_r_000000_0
2016-02-09 15:32:10,347 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 15:32:10,348 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 15:32:10,355 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@9240189
2016-02-09 15:32:10,371 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-09 15:32:10,378 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local681351725_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-09 15:32:10,430 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local681351725_0001_m_000000_0 decomp: 161 len: 165 to MEMORY
2016-02-09 15:32:10,449 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 161 bytes from map-output for attempt_local681351725_0001_m_000000_0
2016-02-09 15:32:10,453 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 161, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->161
2016-02-09 15:32:10,454 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-09 15:32:10,456 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 15:32:10,457 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-09 15:32:10,465 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 15:32:10,465 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-09 15:32:10,467 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 161 bytes to disk to satisfy reduce memory limit
2016-02-09 15:32:10,468 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2016-02-09 15:32:10,469 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-09 15:32:10,469 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 15:32:10,470 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-09 15:32:10,470 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 15:32:10,477 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-09 15:32:10,486 INFO org.apache.hadoop.mapred.Task: Task:attempt_local681351725_0001_r_000000_0 is done. And is in the process of committing
2016-02-09 15:32:10,488 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 15:32:10,488 INFO org.apache.hadoop.mapred.Task: Task attempt_local681351725_0001_r_000000_0 is allowed to commit now
2016-02-09 15:32:10,489 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local681351725_0001_r_000000_0' to file:/home/cloudera/Desktop/hw2_output/_temporary/0/task_local681351725_0001_r_000000
2016-02-09 15:32:10,494 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-09 15:32:10,495 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local681351725_0001_r_000000_0' done.
2016-02-09 15:32:10,495 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local681351725_0001_r_000000_0
2016-02-09 15:32:10,495 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-09 15:32:10,817 INFO org.apache.hadoop.mapreduce.Job: Job job_local681351725_0001 running in uber mode : false
2016-02-09 15:32:10,818 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-09 15:32:10,819 INFO org.apache.hadoop.mapreduce.Job: Job job_local681351725_0001 completed successfully
2016-02-09 15:32:10,845 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1288
		FILE: Number of bytes written=524882
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=12
		Map output bytes=135
		Map output materialized bytes=165
		Input split bytes=118
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=165
		Reduce input records=12
		Reduce output records=4
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=44
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=47
2016-02-09 15:40:19,976 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-02-09 15:40:20,746 INFO org.apache.hadoop.conf.Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
2016-02-09 15:40:20,752 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2016-02-09 15:40:21,407 WARN org.apache.hadoop.mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2016-02-09 15:40:21,410 WARN org.apache.hadoop.mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
2016-02-09 15:40:21,422 INFO org.apache.hadoop.mapreduce.lib.input.FileInputFormat: Total input paths to process : 1
2016-02-09 15:40:21,477 INFO org.apache.hadoop.mapreduce.JobSubmitter: number of splits:1
2016-02-09 15:40:21,827 INFO org.apache.hadoop.mapreduce.JobSubmitter: Submitting tokens for job: job_local960538719_0001
2016-02-09 15:40:22,458 INFO org.apache.hadoop.mapreduce.Job: The url to track the job: http://localhost:8080/
2016-02-09 15:40:22,459 INFO org.apache.hadoop.mapreduce.Job: Running job: job_local960538719_0001
2016-02-09 15:40:22,470 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter set in config null
2016-02-09 15:40:22,494 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 15:40:22,497 INFO org.apache.hadoop.mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2016-02-09 15:40:22,682 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for map tasks
2016-02-09 15:40:22,683 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local960538719_0001_m_000000_0
2016-02-09 15:40:22,769 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 15:40:22,817 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 15:40:22,831 INFO org.apache.hadoop.mapred.MapTask: Processing split: file:/home/cloudera/workspace/wordcount/hw2_inputfile:0+289
2016-02-09 15:40:23,019 INFO org.apache.hadoop.mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2016-02-09 15:40:23,019 INFO org.apache.hadoop.mapred.MapTask: mapreduce.task.io.sort.mb: 100
2016-02-09 15:40:23,019 INFO org.apache.hadoop.mapred.MapTask: soft limit at 83886080
2016-02-09 15:40:23,020 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufvoid = 104857600
2016-02-09 15:40:23,020 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396; length = 6553600
2016-02-09 15:40:23,032 INFO org.apache.hadoop.mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2016-02-09 15:40:23,051 INFO org.apache.hadoop.mapred.LocalJobRunner: 
2016-02-09 15:40:23,052 INFO org.apache.hadoop.mapred.MapTask: Starting flush of map output
2016-02-09 15:40:23,052 INFO org.apache.hadoop.mapred.MapTask: Spilling map output
2016-02-09 15:40:23,052 INFO org.apache.hadoop.mapred.MapTask: bufstart = 0; bufend = 135; bufvoid = 104857600
2016-02-09 15:40:23,052 INFO org.apache.hadoop.mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
2016-02-09 15:40:23,079 INFO org.apache.hadoop.mapred.MapTask: Finished spill 0
2016-02-09 15:40:23,087 INFO org.apache.hadoop.mapred.Task: Task:attempt_local960538719_0001_m_000000_0 is done. And is in the process of committing
2016-02-09 15:40:23,109 INFO org.apache.hadoop.mapred.LocalJobRunner: map
2016-02-09 15:40:23,112 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local960538719_0001_m_000000_0' done.
2016-02-09 15:40:23,112 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local960538719_0001_m_000000_0
2016-02-09 15:40:23,113 INFO org.apache.hadoop.mapred.LocalJobRunner: map task executor complete.
2016-02-09 15:40:23,116 INFO org.apache.hadoop.mapred.LocalJobRunner: Waiting for reduce tasks
2016-02-09 15:40:23,117 INFO org.apache.hadoop.mapred.LocalJobRunner: Starting task: attempt_local960538719_0001_r_000000_0
2016-02-09 15:40:23,146 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
2016-02-09 15:40:23,148 INFO org.apache.hadoop.mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
2016-02-09 15:40:23,152 INFO org.apache.hadoop.mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@31593221
2016-02-09 15:40:23,215 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: MergerManager: memoryLimit=679778688, maxSingleShuffleLimit=169944672, mergeThreshold=448653952, ioSortFactor=10, memToMemMergeOutputsThreshold=10
2016-02-09 15:40:23,235 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: attempt_local960538719_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
2016-02-09 15:40:23,387 INFO org.apache.hadoop.mapreduce.task.reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local960538719_0001_m_000000_0 decomp: 161 len: 165 to MEMORY
2016-02-09 15:40:23,421 INFO org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput: Read 161 bytes from map-output for attempt_local960538719_0001_m_000000_0
2016-02-09 15:40:23,430 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 161, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->161
2016-02-09 15:40:23,432 INFO org.apache.hadoop.mapreduce.task.reduce.EventFetcher: EventFetcher is interrupted.. Returning
2016-02-09 15:40:23,433 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 15:40:23,438 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
2016-02-09 15:40:23,465 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 15:40:23,465 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-09 15:40:23,470 INFO org.apache.hadoop.mapreduce.Job: Job job_local960538719_0001 running in uber mode : false
2016-02-09 15:40:23,473 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 0%
2016-02-09 15:40:23,478 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merged 1 segments, 161 bytes to disk to satisfy reduce memory limit
2016-02-09 15:40:23,484 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 1 files, 165 bytes from disk
2016-02-09 15:40:23,484 INFO org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
2016-02-09 15:40:23,485 INFO org.apache.hadoop.mapred.Merger: Merging 1 sorted segments
2016-02-09 15:40:23,486 INFO org.apache.hadoop.mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 151 bytes
2016-02-09 15:40:23,495 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 15:40:23,513 INFO org.apache.hadoop.conf.Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
2016-02-09 15:40:23,539 INFO org.apache.hadoop.mapred.Task: Task:attempt_local960538719_0001_r_000000_0 is done. And is in the process of committing
2016-02-09 15:40:23,549 INFO org.apache.hadoop.mapred.LocalJobRunner: 1 / 1 copied.
2016-02-09 15:40:23,549 INFO org.apache.hadoop.mapred.Task: Task attempt_local960538719_0001_r_000000_0 is allowed to commit now
2016-02-09 15:40:23,550 INFO org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter: Saved output of task 'attempt_local960538719_0001_r_000000_0' to file:/home/cloudera/Desktop/hw2_output/_temporary/0/task_local960538719_0001_r_000000
2016-02-09 15:40:23,560 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce > reduce
2016-02-09 15:40:23,560 INFO org.apache.hadoop.mapred.Task: Task 'attempt_local960538719_0001_r_000000_0' done.
2016-02-09 15:40:23,560 INFO org.apache.hadoop.mapred.LocalJobRunner: Finishing task: attempt_local960538719_0001_r_000000_0
2016-02-09 15:40:23,560 INFO org.apache.hadoop.mapred.LocalJobRunner: reduce task executor complete.
2016-02-09 15:40:24,474 INFO org.apache.hadoop.mapreduce.Job:  map 100% reduce 100%
2016-02-09 15:40:24,474 INFO org.apache.hadoop.mapreduce.Job: Job job_local960538719_0001 completed successfully
2016-02-09 15:40:24,488 INFO org.apache.hadoop.mapreduce.Job: Counters: 33
	File System Counters
		FILE: Number of bytes read=1288
		FILE: Number of bytes written=524882
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=12
		Map output bytes=135
		Map output materialized bytes=165
		Input split bytes=118
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=165
		Reduce input records=12
		Reduce output records=4
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=81
		CPU time spent (ms)=0
		Physical memory (bytes) snapshot=0
		Virtual memory (bytes) snapshot=0
		Total committed heap usage (bytes)=331227136
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=289
	File Output Format Counters 
		Bytes Written=47
